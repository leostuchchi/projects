{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003d3879",
   "metadata": {
    "id": "003d3879"
   },
   "source": [
    "# PyTorch, EMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cd4ef",
   "metadata": {},
   "source": [
    "# Подготовка модели распознавания рукописных букв и цифр"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d8d34",
   "metadata": {},
   "source": [
    "# План исследований:\n",
    "\n",
    "## 1. - Подготовка отраженных и перевернутых данных с нормализацией\n",
    "\n",
    "* Обучение и дообучение модели с сохранением промежуточных результатов: \n",
    "\n",
    " - 10 эпох, lr=0.001\n",
    "\n",
    " - 15 эпох, lr=0.0005\n",
    "\n",
    " - 5 эпох, lr=0.00001\n",
    "\n",
    "\n",
    "\n",
    "## 2. - Подготовка отраженных и перевернутых данных с нормализацией\n",
    "\n",
    "     с использованием методов Eroding, Dilating и Smoothing Images\n",
    "\n",
    "* Обучение и дообучение модели с сохранением промежуточных результатов:\n",
    "\n",
    " - 10 эпох, lr=0.001\n",
    "\n",
    " - 15 эпох, lr=0.0005\n",
    "\n",
    " - 5 эпох, lr=0.00001\n",
    "\n",
    "\n",
    "## 3. - Оценка модели\n",
    "\n",
    " - Предварительная оценка модели\n",
    "\n",
    " - Оценка модели на разных типах данных\n",
    " \n",
    "\n",
    "## 4. - Резульаты и выводы о проделанной работе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919cb9f",
   "metadata": {
    "id": "f919cb9f"
   },
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d826ec1",
   "metadata": {
    "id": "2d826ec1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import EMNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "iTaSE6noHgJa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24275,
     "status": "ok",
     "timestamp": 1736085791682,
     "user": {
      "displayName": "Leonard Stuchilin",
      "userId": "12835425704178441738"
     },
     "user_tz": -120
    },
    "id": "iTaSE6noHgJa",
    "outputId": "2a91620a-f1d0-4fa0-85a4-ce84331c029d"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ac4f0",
   "metadata": {
    "id": "c84ac4f0"
   },
   "source": [
    "# Получение, трансформация, нормализация и контроль данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d6caec",
   "metadata": {
    "id": "c9d6caec"
   },
   "outputs": [],
   "source": [
    "# Определение трансформаций для нормализации данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Нормализация по среднему и стандартному отклонению\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xdL11aKhHxmL",
   "metadata": {
    "id": "xdL11aKhHxmL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "128421ce",
   "metadata": {
    "id": "128421ce"
   },
   "outputs": [],
   "source": [
    "# Загрузка обучающего набора данных с трансформациями\n",
    "train_data = EMNIST('data_r/', 'balanced', train=True, download=True,\n",
    "                transform=torchvision.transforms.Compose([ # Поворот и отражение\n",
    "                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741504e0",
   "metadata": {
    "id": "741504e0"
   },
   "outputs": [],
   "source": [
    "# Загрузка тестового набора данных с трансформациями\n",
    "test_data = EMNIST('data_r/', 'balanced', train=False,\n",
    "                transform=torchvision.transforms.Compose([ # Поворот и отражение\n",
    "                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1864e3f0",
   "metadata": {
    "id": "1864e3f0"
   },
   "outputs": [],
   "source": [
    "# получение маппинга\n",
    "with open('emnist-balanced-mapping.txt', 'r') as f:\n",
    "    mapping = f.readlines()\n",
    "\n",
    "#mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "092862d6",
   "metadata": {
    "id": "092862d6"
   },
   "outputs": [],
   "source": [
    "# Создаем словарь соответствий\n",
    "label_dict = {}\n",
    "for entry in mapping:\n",
    "    label, ascii_code = map(int, entry.split())\n",
    "    label_dict[label] = chr(ascii_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ccc7f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Проверяем корректность изображений\n",
    "fig, axs = plt.subplots(1, 10, figsize=(20, 5))\n",
    "for i in range(10):\n",
    "    random_index = np.random.randint(0, len(train_data))\n",
    "    #print('Random index:', random_index)\n",
    "    image, label = train_data[random_index]\n",
    "\n",
    "    # Преобразование изображения в NumPy массив для корректного отображения\n",
    "    image_np = image.numpy()  # Прямое преобразование в NumPy массив\n",
    "\n",
    "    # Убираем размерность канала (если она есть)\n",
    "    if image_np.shape[0] == 1:  # Если канал один (черно-белое изображение)\n",
    "        image_np = image_np.squeeze(0)  # Убираем размерность канала\n",
    "\n",
    "    # Отображаем изображение\n",
    "    axs[i].imshow(image_np, cmap='gray')\n",
    "    axs[i].set_title(label_dict[label])  # Используем словарь для отображения метки\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7473f0",
   "metadata": {
    "id": "dc7473f0"
   },
   "outputs": [],
   "source": [
    "# Создание загрузчиков данных\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62437173",
   "metadata": {
    "id": "62437173"
   },
   "source": [
    "## Моделирование\n",
    "\n",
    "Сверточная нейронная сеть (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "EyP8MjIwu7_m",
   "metadata": {
    "id": "EyP8MjIwu7_m"
   },
   "outputs": [],
   "source": [
    "# Определение модели\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Убедитесь в правильном размере\n",
    "        self.fc2 = nn.Linear(128, 47)  # Для 47 классов\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31c711f0",
   "metadata": {
    "id": "31c711f0"
   },
   "outputs": [],
   "source": [
    "# Инициализация модели\n",
    "model_cnn = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29e648ed",
   "metadata": {
    "id": "29e648ed"
   },
   "outputs": [],
   "source": [
    "# Оптимизатор и функция потерь\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.001)  # Используем Adam с малой скоростью обучения\n",
    "loss_function = nn.CrossEntropyLoss()  # Функция потерь для многоклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10beb51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2046267,
     "status": "ok",
     "timestamp": 1736087928675,
     "user": {
      "displayName": "Leonard Stuchilin",
      "userId": "12835425704178441738"
     },
     "user_tz": -120
    },
    "id": "a10beb51",
    "outputId": "54124300-58f5-4d92-9bad-5781ed0931fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6164\n",
      "Validation Accuracy: 0.8476\n",
      "Epoch 2/10, Loss: 0.3942\n",
      "Validation Accuracy: 0.8606\n",
      "Epoch 3/10, Loss: 0.3456\n",
      "Validation Accuracy: 0.8669\n",
      "Epoch 4/10, Loss: 0.3131\n",
      "Validation Accuracy: 0.8685\n",
      "Epoch 5/10, Loss: 0.2871\n",
      "Validation Accuracy: 0.8764\n",
      "Epoch 6/10, Loss: 0.2653\n",
      "Validation Accuracy: 0.8786\n",
      "Epoch 7/10, Loss: 0.2461\n",
      "Validation Accuracy: 0.8721\n",
      "Epoch 8/10, Loss: 0.2279\n",
      "Validation Accuracy: 0.8831\n",
      "Epoch 9/10, Loss: 0.2115\n",
      "Validation Accuracy: 0.8778\n",
      "Epoch 10/10, Loss: 0.1964\n",
      "Validation Accuracy: 0.8773\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model_cnn.train()  # Устанавливаем режим обучения\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()  # Обнуляем градиенты\n",
    "        output = model_cnn(data)  # Прямой проход через модель\n",
    "        loss = loss_function(output, target)  # Вычисление потерь\n",
    "        loss.backward()  # Обратный проход (вычисление градиентов)\n",
    "        optimizer.step()  # Обновление параметров\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Валидация модели после каждой эпохи\n",
    "    model_cnn.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model_cnn(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "SMcPKBvhjJal",
   "metadata": {
    "id": "SMcPKBvhjJal"
   },
   "outputs": [],
   "source": [
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bL7rLSXpZ6te",
   "metadata": {
    "id": "bL7rLSXpZ6te"
   },
   "outputs": [],
   "source": [
    "# Сохранение модели в формате .ckpt\n",
    "torch.save(model_cnn.state_dict(), 'data/model_a.ckpt')\n",
    "\n",
    "# Сохранение обученной модели\n",
    "checkpoint = {\n",
    "    'model_state_dict': model_cnn.state_dict(),  # Состояние модели\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # Состояние оптимизатора\n",
    "    'epoch': n_epoch  # Текущий номер эпохи (если нужно возобновить обучение)\n",
    "}\n",
    "\n",
    "# Сохранение контрольной точки в файл .ckpt\n",
    "torch.save(checkpoint, 'data/model_a_checkpoint.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nb0B86Pnjbm2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1736087973097,
     "user": {
      "displayName": "Leonard Stuchilin",
      "userId": "12835425704178441738"
     },
     "user_tz": -120
    },
    "id": "nb0B86Pnjbm2",
    "outputId": "65581ba4-a600-4284-c64a-8e597a9bcf21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5033/725509854.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('data/model_a_checkpoint.ckpt')\n",
      "/tmp/ipykernel_5033/725509854.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_cnn.load_state_dict(torch.load('data/model_a.ckpt'))  # Замените на путь к вашей модели\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка контрольной точки\n",
    "checkpoint = torch.load('data/model_a_checkpoint.ckpt')\n",
    "\n",
    "# Восстановление состояния модели и оптимизатора\n",
    "model_cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Если нужно, можно восстановить номер эпохи\n",
    "n_epoch = checkpoint['epoch']\n",
    "print(n_epoch)\n",
    "\n",
    "# Восстановление номера эпохи\n",
    "start_epoch = checkpoint['epoch'] + 1  # Начинаем с следующей эпохи\n",
    "\n",
    "# Параметры для продолжения обучения\n",
    "n_epochs_to_continue = 15  # Количество дополнительных эпох\n",
    "\n",
    "# Загрузка предварительно обученной модели\n",
    "model_cnn = CNNModel()  # Предполагается, что модель определена\n",
    "model_cnn.load_state_dict(torch.load('data/model_a.ckpt'))  # Замените на путь к вашей модели\n",
    "#model.eval()  # Установка модели в режим оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "IYqexdOGNSuh",
   "metadata": {
    "id": "IYqexdOGNSuh"
   },
   "outputs": [],
   "source": [
    "# Оптимизатор и функция потерь\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.0005)  # Используем Adam с малой скоростью обучения\n",
    "loss_function = nn.CrossEntropyLoss()  # Функция потерь для многоклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "BmC1BHpso9IJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 992249,
     "status": "ok",
     "timestamp": 1736088979582,
     "user": {
      "displayName": "Leonard Stuchilin",
      "userId": "12835425704178441738"
     },
     "user_tz": -120
    },
    "id": "BmC1BHpso9IJ",
    "outputId": "fa2baf46-e5eb-4de6-bd16-6d8eee87225a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/26, Loss: 0.1569\n",
      "Validation Accuracy: 0.8753\n",
      "Epoch 12/26, Loss: 0.1406\n",
      "Validation Accuracy: 0.8781\n",
      "Epoch 13/26, Loss: 0.1297\n",
      "Validation Accuracy: 0.8781\n",
      "Epoch 14/26, Loss: 0.1210\n",
      "Validation Accuracy: 0.8771\n",
      "Epoch 15/26, Loss: 0.1125\n",
      "Validation Accuracy: 0.8744\n",
      "Epoch 16/26, Loss: 0.1054\n",
      "Validation Accuracy: 0.8705\n",
      "Epoch 17/26, Loss: 0.0982\n",
      "Validation Accuracy: 0.8731\n",
      "Epoch 18/26, Loss: 0.0919\n",
      "Validation Accuracy: 0.8677\n",
      "Epoch 19/26, Loss: 0.0865\n",
      "Validation Accuracy: 0.8683\n",
      "Epoch 20/26, Loss: 0.0807\n",
      "Validation Accuracy: 0.8684\n",
      "Epoch 21/26, Loss: 0.0758\n",
      "Validation Accuracy: 0.8684\n",
      "Epoch 22/26, Loss: 0.0710\n",
      "Validation Accuracy: 0.8650\n",
      "Epoch 23/26, Loss: 0.0672\n",
      "Validation Accuracy: 0.8674\n",
      "Epoch 24/26, Loss: 0.0636\n",
      "Validation Accuracy: 0.8660\n",
      "Epoch 25/26, Loss: 0.0603\n",
      "Validation Accuracy: 0.8679\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch + n_epochs_to_continue):\n",
    "    model_cnn.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model_cnn(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch}/{start_epoch + n_epochs_to_continue}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Валидация модели после каждой эпохи\n",
    "    model_cnn.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model_cnn(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nEZbI-y0pYUI",
   "metadata": {
    "id": "nEZbI-y0pYUI"
   },
   "outputs": [],
   "source": [
    "# Сохранение модели в формате .ckpt\n",
    "torch.save(model_cnn.state_dict(), 'data/model_a_1.ckpt')\n",
    "\n",
    "# Сохранение обученной модели\n",
    "new_checkpoint = {\n",
    "    'model_state_dict': model_cnn.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': start_epoch + n_epochs_to_continue - 1,\n",
    "}\n",
    "# Сохранение контрольной точки в файл .ckpt\n",
    "torch.save(new_checkpoint, 'data/model_a_checkpoint_1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5587128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5033/178477228.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('data/model_a_checkpoint_1.ckpt')\n",
      "/tmp/ipykernel_5033/178477228.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_cnn.load_state_dict(torch.load('data/model_a_1.ckpt'))  # Замените на путь к вашей модели\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка контрольной точки\n",
    "checkpoint = torch.load('data/model_a_checkpoint_1.ckpt')\n",
    "\n",
    "# Восстановление состояния модели и оптимизатора\n",
    "model_cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Если нужно, можно восстановить номер эпохи\n",
    "n_epoch = checkpoint['epoch']\n",
    "print(n_epoch)\n",
    "\n",
    "# Восстановление номера эпохи\n",
    "start_epoch = checkpoint['epoch'] + 1  # Начинаем с следующей эпохи\n",
    "\n",
    "# Параметры для продолжения обучения\n",
    "n_epochs_to_continue = 5  # Количество дополнительных эпох\n",
    "\n",
    "# Загрузка предварительно обученной модели\n",
    "model_cnn = CNNModel()  # Предполагается, что модель определена\n",
    "model_cnn.load_state_dict(torch.load('data/model_a_1.ckpt'))  # Замените на путь к вашей модели\n",
    "#model.eval()  # Установка модели в режим оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33020c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизатор и функция потерь\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.00001)  # Используем Adam с малой скоростью обучения\n",
    "loss_function = nn.CrossEntropyLoss()  # Функция потерь для многоклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2ae3504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/31, Loss: 0.0442\n",
      "Validation Accuracy: 0.8689\n",
      "Epoch 27/31, Loss: 0.0396\n",
      "Validation Accuracy: 0.8697\n",
      "Epoch 28/31, Loss: 0.0379\n",
      "Validation Accuracy: 0.8693\n",
      "Epoch 29/31, Loss: 0.0368\n",
      "Validation Accuracy: 0.8702\n",
      "Epoch 30/31, Loss: 0.0360\n",
      "Validation Accuracy: 0.8695\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch + n_epochs_to_continue):\n",
    "    model_cnn.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model_cnn(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch}/{start_epoch + n_epochs_to_continue}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Валидация модели после каждой эпохи\n",
    "    model_cnn.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model_cnn(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d7c1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели в формате .ckpt\n",
    "torch.save(model_cnn.state_dict(), 'data/model_a_2.ckpt')\n",
    "\n",
    "# Сохранение обученной модели\n",
    "new_checkpoint = {\n",
    "    'model_state_dict': model_cnn.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': start_epoch + n_epochs_to_continue - 1,\n",
    "}\n",
    "# Сохранение контрольной точки в файл .ckpt\n",
    "torch.save(new_checkpoint, 'data/model_a_checkpoint_2.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841Er5mBvz8K",
   "metadata": {
    "id": "841Er5mBvz8K"
   },
   "source": [
    "# Дообучение на преобразованных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "vA4Ec5axtZtK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1736088999446,
     "user": {
      "displayName": "Leonard Stuchilin",
      "userId": "12835425704178441738"
     },
     "user_tz": -120
    },
    "id": "vA4Ec5axtZtK",
    "outputId": "ad098178-fd70-4cb3-e93d-41c9f5a9fa8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5033/276588742.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('data/model_a_checkpoint_2.ckpt')\n",
      "/tmp/ipykernel_5033/276588742.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_cnn.load_state_dict(torch.load('data/model_a_2.ckpt'))  # Замените на путь к вашей модели\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка контрольной точки\n",
    "checkpoint = torch.load('data/model_a_checkpoint_2.ckpt')\n",
    "\n",
    "# Восстановление состояния модели и оптимизатора\n",
    "model_cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Если нужно, можно восстановить номер эпохи\n",
    "n_epoch = checkpoint['epoch']\n",
    "print(n_epoch)\n",
    "\n",
    "# Восстановление номера эпохи\n",
    "start_epoch = checkpoint['epoch'] + 1  # Начинаем с следующей эпохи\n",
    "\n",
    "# Параметры для продолжения обучения\n",
    "n_epochs_to_continue = 10  # Количество дополнительных эпох\n",
    "\n",
    "# Загрузка предварительно обученной модели\n",
    "model_cnn = CNNModel()  # Предполагается, что модель определена\n",
    "model_cnn.load_state_dict(torch.load('data/model_a_2.ckpt'))  # Замените на путь к вашей модели\n",
    "#model.eval()  # Установка модели в режим оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ewEKEKkUvRiy",
   "metadata": {
    "id": "ewEKEKkUvRiy"
   },
   "outputs": [],
   "source": [
    "# Оптимизатор и функция потерь\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.001)  # Используем Adam с малой скоростью обучения\n",
    "loss_function = nn.CrossEntropyLoss()  # Функция потерь для многоклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "G7GDvPh3uwJh",
   "metadata": {
    "id": "G7GDvPh3uwJh"
   },
   "outputs": [],
   "source": [
    "'''Для обработки изображений х EMNIST с использованием методов Eroding, Dilating и Smoothing Images,\n",
    " создадим функцию, для предобработки перед передачей изображений в модель'''\n",
    "\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Преобразуем изображение PIL в массив NumPy\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Применяем сглаживание (Gaussian Blur)\n",
    "    img_blurred = cv2.GaussianBlur(img_np, (5, 5), 0)\n",
    "\n",
    "    # Применяем эрозию\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_eroded = cv2.erode(img_blurred, kernel, iterations=1)\n",
    "\n",
    "    # Применяем дилатацию\n",
    "    img_dilated = cv2.dilate(img_eroded, kernel, iterations=1)\n",
    "\n",
    "    # Преобразуем обратно в PIL\n",
    "    img_processed = Image.fromarray(img_dilated)\n",
    "\n",
    "    return img_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "RW3hGYbj0IKV",
   "metadata": {
    "id": "RW3hGYbj0IKV"
   },
   "outputs": [],
   "source": [
    "# Определение трансформаций для нормализации данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Нормализация по среднему и стандартному отклонению\n",
    "])\n",
    "\n",
    "# использованием методов Eroding, Dilating и Smoothing Images\n",
    "# Загрузка обучающего набора данных с трансформациями\n",
    "train_data = EMNIST('data_e_r/', 'balanced', train=True, download=True,\n",
    "                transform=torchvision.transforms.Compose([ \n",
    "                    # Применяем обработку изображения\n",
    "                    preprocess_image,\n",
    "                    # Поворот и отражение\n",
    "                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))\n",
    "\n",
    "# использованием методов Eroding, Dilating и Smoothing Images\n",
    "# Загрузка тестового набора данных с трансформациями\n",
    "test_data = EMNIST('data_e_r/', 'balanced', train=False,\n",
    "                transform=torchvision.transforms.Compose([ \n",
    "                    # Применяем обработку изображения\n",
    "                    preprocess_image,\n",
    "                    # Поворот и отражение\n",
    "                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "XVvL4K6y0bKY",
   "metadata": {
    "id": "XVvL4K6y0bKY"
   },
   "outputs": [],
   "source": [
    "# Создание загрузчиков данных\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "flbXnFyg1E9D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1219251,
     "status": "ok",
     "timestamp": 1736090248516,
     "user": {
      "displayName": "Leonard Stuchilin",
      "userId": "12835425704178441738"
     },
     "user_tz": -120
    },
    "id": "flbXnFyg1E9D",
    "outputId": "828a6341-f098-4628-f1dc-8d7256013cc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/41, Loss: 0.3349\n",
      "Validation Accuracy: 0.8680\n",
      "Epoch 32/41, Loss: 0.2468\n",
      "Validation Accuracy: 0.8670\n",
      "Epoch 33/41, Loss: 0.2161\n",
      "Validation Accuracy: 0.8694\n",
      "Epoch 34/41, Loss: 0.1967\n",
      "Validation Accuracy: 0.8677\n",
      "Epoch 35/41, Loss: 0.1793\n",
      "Validation Accuracy: 0.8685\n",
      "Epoch 36/41, Loss: 0.1650\n",
      "Validation Accuracy: 0.8693\n",
      "Epoch 37/41, Loss: 0.1539\n",
      "Validation Accuracy: 0.8661\n",
      "Epoch 38/41, Loss: 0.1432\n",
      "Validation Accuracy: 0.8712\n",
      "Epoch 39/41, Loss: 0.1340\n",
      "Validation Accuracy: 0.8651\n",
      "Epoch 40/41, Loss: 0.1259\n",
      "Validation Accuracy: 0.8661\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch + n_epochs_to_continue):\n",
    "    model_cnn.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model_cnn(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch}/{start_epoch + n_epochs_to_continue}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Валидация модели после каждой эпохи\n",
    "    model_cnn.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model_cnn(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "XXEsRb3NzOft",
   "metadata": {
    "id": "XXEsRb3NzOft"
   },
   "outputs": [],
   "source": [
    "# Сохранение модели в формате .ckpt\n",
    "torch.save(model_cnn.state_dict(), 'data/model_a_3.ckpt')\n",
    "\n",
    "# Сохранение обученной модели\n",
    "new_checkpoint = {\n",
    "    'model_state_dict': model_cnn.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': start_epoch + n_epochs_to_continue - 1,\n",
    "}\n",
    "# Сохранение контрольной точки в файл .ckpt\n",
    "torch.save(new_checkpoint, 'data/model_a_checkpoint_3.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0b230",
   "metadata": {},
   "source": [
    "Первый этап (начальное обучение):\n",
    "\n",
    "    Скорость обучения: Начните с более высокой скорости обучения, например, 0.001. Это поможет модели быстро адаптироваться к данным.\n",
    "    Количество эпох: Используйте большее количество эпох (например, 10-20), чтобы модель могла хорошо обучиться на данных.\n",
    "\n",
    "Второй этап (дообучение):\n",
    "\n",
    "    Скорость обучения: Уменьшите скорость обучения до 0.0005 или 0.0001. Это позволит модели более точно подстраиваться под данные.\n",
    "    Количество эпох: Увеличьте количество эпох (например, 20-30), чтобы модель могла дообучиться на более низкой скорости.\n",
    "\n",
    "Третий этап (файн-тюнинг):\n",
    "\n",
    "    Скорость обучения: Установите еще более низкую скорость обучения (например, 0.00001). Это позволит модели делать очень мелкие корректировки.\n",
    "    Количество эпох: Используйте меньшее количество эпох (например, 5-10), так как модель уже близка к оптимальному состоянию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "070af963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5033/131934471.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('data/model_a_checkpoint_3.ckpt')\n",
      "/tmp/ipykernel_5033/131934471.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_cnn.load_state_dict(torch.load('data/model_a_3.ckpt'))  # Замените на путь к вашей модели\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка контрольной точки\n",
    "checkpoint = torch.load('data/model_a_checkpoint_3.ckpt')\n",
    "\n",
    "# Восстановление состояния модели и оптимизатора\n",
    "model_cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Если нужно, можно восстановить номер эпохи\n",
    "n_epoch = checkpoint['epoch']\n",
    "print(n_epoch)\n",
    "\n",
    "# Восстановление номера эпохи\n",
    "start_epoch = checkpoint['epoch'] + 1  # Начинаем с следующей эпохи\n",
    "\n",
    "# Параметры для продолжения обучения\n",
    "n_epochs_to_continue = 15  # Количество дополнительных эпох\n",
    "\n",
    "# Загрузка предварительно обученной модели\n",
    "model_cnn = CNNModel()  # Предполагается, что модель определена\n",
    "model_cnn.load_state_dict(torch.load('data/model_a_3.ckpt'))  # Замените на путь к вашей модели\n",
    "#model.eval()  # Установка модели в режим оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "764fc216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизатор и функция потерь\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.0001)  # Используем Adam с малой скоростью обучения\n",
    "loss_function = nn.CrossEntropyLoss()  # Функция потерь для многоклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96858495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание загрузчиков данных\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15f74f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/56, Loss: 0.0831\n",
      "Validation Accuracy: 0.8719\n",
      "Epoch 42/56, Loss: 0.0727\n",
      "Validation Accuracy: 0.8713\n",
      "Epoch 43/56, Loss: 0.0681\n",
      "Validation Accuracy: 0.8726\n",
      "Epoch 44/56, Loss: 0.0650\n",
      "Validation Accuracy: 0.8709\n",
      "Epoch 45/56, Loss: 0.0620\n",
      "Validation Accuracy: 0.8719\n",
      "Epoch 46/56, Loss: 0.0596\n",
      "Validation Accuracy: 0.8705\n",
      "Epoch 47/56, Loss: 0.0572\n",
      "Validation Accuracy: 0.8713\n",
      "Epoch 48/56, Loss: 0.0550\n",
      "Validation Accuracy: 0.8692\n",
      "Epoch 49/56, Loss: 0.0530\n",
      "Validation Accuracy: 0.8703\n",
      "Epoch 50/56, Loss: 0.0511\n",
      "Validation Accuracy: 0.8684\n",
      "Epoch 51/56, Loss: 0.0493\n",
      "Validation Accuracy: 0.8700\n",
      "Epoch 52/56, Loss: 0.0475\n",
      "Validation Accuracy: 0.8682\n",
      "Epoch 53/56, Loss: 0.0462\n",
      "Validation Accuracy: 0.8665\n",
      "Epoch 54/56, Loss: 0.0445\n",
      "Validation Accuracy: 0.8693\n",
      "Epoch 55/56, Loss: 0.0429\n",
      "Validation Accuracy: 0.8679\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch + n_epochs_to_continue):\n",
    "    model_cnn.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model_cnn(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch}/{start_epoch + n_epochs_to_continue}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Валидация модели после каждой эпохи\n",
    "    model_cnn.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model_cnn(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1630b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели в формате .ckpt\n",
    "torch.save(model_cnn.state_dict(), 'data/model_a_4.ckpt')\n",
    "\n",
    "# Сохранение обученной модели\n",
    "new_checkpoint = {\n",
    "    'model_state_dict': model_cnn.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': start_epoch + n_epochs_to_continue - 1,\n",
    "}\n",
    "# Сохранение контрольной точки в файл .ckpt\n",
    "torch.save(new_checkpoint, 'data/model_a_checkpoint_4.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061349d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b9a1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизатор и функция потерь\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.00001)  # Используем Adam с малой скоростью обучения\n",
    "loss_function = nn.CrossEntropyLoss()  # Функция потерь для многоклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f522872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5033/114102098.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('data/model_a_checkpoint_4.ckpt')\n",
      "/tmp/ipykernel_5033/114102098.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_cnn.load_state_dict(torch.load('data/model_a_4.ckpt'))  # Замените на путь к вашей модели\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка контрольной точки\n",
    "checkpoint = torch.load('data/model_a_checkpoint_4.ckpt')\n",
    "\n",
    "# Восстановление состояния модели и оптимизатора\n",
    "model_cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Если нужно, можно восстановить номер эпохи\n",
    "n_epoch = checkpoint['epoch']\n",
    "print(n_epoch)\n",
    "\n",
    "# Восстановление номера эпохи\n",
    "start_epoch = checkpoint['epoch'] + 1  # Начинаем с следующей эпохи\n",
    "\n",
    "# Параметры для продолжения обучения\n",
    "n_epochs_to_continue = 5  # Количество дополнительных эпох\n",
    "\n",
    "# Загрузка предварительно обученной модели\n",
    "model_cnn = CNNModel()  # Предполагается, что модель определена\n",
    "model_cnn.load_state_dict(torch.load('data/model_a_4.ckpt'))  # Замените на путь к вашей модели\n",
    "#model.eval()  # Установка модели в режим оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a5c8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание загрузчиков данных\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "377637c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/61, Loss: 0.0400\n",
      "Validation Accuracy: 0.8680\n",
      "Epoch 57/61, Loss: 0.0399\n",
      "Validation Accuracy: 0.8676\n",
      "Epoch 58/61, Loss: 0.0400\n",
      "Validation Accuracy: 0.8679\n",
      "Epoch 59/61, Loss: 0.0401\n",
      "Validation Accuracy: 0.8676\n",
      "Epoch 60/61, Loss: 0.0400\n",
      "Validation Accuracy: 0.8676\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch + n_epochs_to_continue):\n",
    "    model_cnn.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model_cnn(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch}/{start_epoch + n_epochs_to_continue}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Валидация модели после каждой эпохи\n",
    "    model_cnn.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model_cnn(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab00d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели в формате .ckpt\n",
    "torch.save(model_cnn.state_dict(), 'data/model_a_5.ckpt')\n",
    "\n",
    "# Сохранение обученной модели\n",
    "new_checkpoint = {\n",
    "    'model_state_dict': model_cnn.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': start_epoch + n_epochs_to_continue - 1,\n",
    "}\n",
    "# Сохранение контрольной точки в файл .ckpt\n",
    "torch.save(new_checkpoint, 'data/model_a_checkpoint_5.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd255db",
   "metadata": {
    "id": "bdd255db"
   },
   "source": [
    "# Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "UlBGRY071lw8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1736094717498,
     "user": {
      "displayName": "Leonard Stuchilin",
      "userId": "12835425704178441738"
     },
     "user_tz": -120
    },
    "id": "UlBGRY071lw8",
    "outputId": "bfa5f8a3-de24-4bdc-9e3c-796a930be478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoches 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5215/1368578123.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('data/model_a_checkpoint_5.ckpt')\n",
      "/tmp/ipykernel_5215/1368578123.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_cnn.load_state_dict(torch.load('data/model_a_5.ckpt'))  # Замените на путь к вашей модели\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn = CNNModel() \n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.00001) \n",
    "\n",
    "# Загрузка контрольной точки\n",
    "checkpoint = torch.load('data/model_a_checkpoint_5.ckpt')\n",
    "\n",
    "# Восстановление состояния модели и оптимизатора\n",
    "model_cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Если нужно, можно восстановить номер эпохи\n",
    "n_epoch = checkpoint['epoch']\n",
    "print('epoches', n_epoch)\n",
    "\n",
    "# Восстановление номера эпохи\n",
    "start_epoch = checkpoint['epoch'] + 1  # Начинаем с следующей эпохи\n",
    "\n",
    "# Параметры для продолжения обучения\n",
    "n_epochs_to_continue = 5  # Количество дополнительных эпох\n",
    "\n",
    "# Загрузка предварительно обученной модели\n",
    "model_cnn = CNNModel()  # Предполагается, что модель определена\n",
    "model_cnn.load_state_dict(torch.load('data/model_a_5.ckpt'))  # Замените на путь к вашей модели\n",
    "#model.eval()  # Установка модели в режим оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "zTPQgrkqiXn-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18393,
     "status": "ok",
     "timestamp": 1736094739693,
     "user": {
      "displayName": "Leonard Stuchilin",
      "userId": "12835425704178441738"
     },
     "user_tz": -120
    },
    "id": "zTPQgrkqiXn-",
    "outputId": "2d0a99fa-0a88-44b1-d850-c7e1a6e8db58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Accuracy of class 0: 0.67\n",
      "1\n",
      "Accuracy of class 1: 0.58\n",
      "2\n",
      "Accuracy of class 2: 0.87\n",
      "3\n",
      "Accuracy of class 3: 0.97\n",
      "4\n",
      "Accuracy of class 4: 0.92\n",
      "5\n",
      "Accuracy of class 5: 0.90\n",
      "6\n",
      "Accuracy of class 6: 0.93\n",
      "7\n",
      "Accuracy of class 7: 0.97\n",
      "8\n",
      "Accuracy of class 8: 0.94\n",
      "9\n",
      "Accuracy of class 9: 0.73\n",
      "A\n",
      "Accuracy of class 10: 0.95\n",
      "B\n",
      "Accuracy of class 11: 0.95\n",
      "C\n",
      "Accuracy of class 12: 0.94\n",
      "D\n",
      "Accuracy of class 13: 0.91\n",
      "E\n",
      "Accuracy of class 14: 0.97\n",
      "F\n",
      "Accuracy of class 15: 0.65\n",
      "G\n",
      "Accuracy of class 16: 0.92\n",
      "H\n",
      "Accuracy of class 17: 0.96\n",
      "I\n",
      "Accuracy of class 18: 0.60\n",
      "J\n",
      "Accuracy of class 19: 0.93\n",
      "K\n",
      "Accuracy of class 20: 0.96\n",
      "L\n",
      "Accuracy of class 21: 0.56\n",
      "M\n",
      "Accuracy of class 22: 0.96\n",
      "N\n",
      "Accuracy of class 23: 0.94\n",
      "O\n",
      "Accuracy of class 24: 0.64\n",
      "P\n",
      "Accuracy of class 25: 0.96\n",
      "Q\n",
      "Accuracy of class 26: 0.93\n",
      "R\n",
      "Accuracy of class 27: 0.96\n",
      "S\n",
      "Accuracy of class 28: 0.91\n",
      "T\n",
      "Accuracy of class 29: 0.92\n",
      "U\n",
      "Accuracy of class 30: 0.91\n",
      "V\n",
      "Accuracy of class 31: 0.93\n",
      "W\n",
      "Accuracy of class 32: 0.99\n",
      "X\n",
      "Accuracy of class 33: 0.95\n",
      "Y\n",
      "Accuracy of class 34: 0.88\n",
      "Z\n",
      "Accuracy of class 35: 0.91\n",
      "a\n",
      "Accuracy of class 36: 0.89\n",
      "b\n",
      "Accuracy of class 37: 0.92\n",
      "d\n",
      "Accuracy of class 38: 0.96\n",
      "e\n",
      "Accuracy of class 39: 0.95\n",
      "f\n",
      "Accuracy of class 40: 0.56\n",
      "g\n",
      "Accuracy of class 41: 0.65\n",
      "h\n",
      "Accuracy of class 42: 0.93\n",
      "n\n",
      "Accuracy of class 43: 0.92\n",
      "q\n",
      "Accuracy of class 44: 0.59\n",
      "r\n",
      "Accuracy of class 45: 0.94\n",
      "t\n",
      "Accuracy of class 46: 0.89\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Инициализация переменных для хранения результатов\n",
    "class_correct = [0] * 47  # Для каждого из 47 классов\n",
    "class_total = [0] * 47\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "with torch.no_grad():\n",
    "    for data, target in val_loader:\n",
    "        output = model_cnn(data)  # Получение предсказаний от модели\n",
    "        _, predicted = torch.max(output, 1)  # Получение индексов классов с максимальным значением вероятности\n",
    "\n",
    "        # Подсчет правильных предсказаний для каждого класса\n",
    "        for i in range(len(target)):\n",
    "            label = target[i].item()  # Получение метки класса\n",
    "            class_correct[label] += (predicted[i] == label).item()  # Увеличение счетчика для правильного предсказания\n",
    "            class_total[label] += 1  # Увеличение общего количества примеров для данного класса\n",
    "\n",
    "# Вывод результатов по каждому классу\n",
    "for i in range(47):\n",
    "    if class_total[i] > 0:  # Избегаем деления на ноль\n",
    "        accuracy = class_correct[i] / class_total[i]\n",
    "        print(label_dict[i])\n",
    "        print(f'Accuracy of class {i}: {accuracy:.2f}')\n",
    "    else:\n",
    "        print(f'Class {i} has no samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c-TroxGiYGt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1736094752875,
     "user": {
      "displayName": "Leonard Stuchilin",
      "userId": "12835425704178441738"
     },
     "user_tz": -120
    },
    "id": "3c-TroxGiYGt",
    "outputId": "369c9d48-d456-4ced-ccf7-d338a6d0b5df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes with accuracy < 0.87:\n",
      "0\n",
      "Accuracy of class 0: 0.67\n",
      "1\n",
      "Accuracy of class 1: 0.58\n",
      "9\n",
      "Accuracy of class 9: 0.73\n",
      "F\n",
      "Accuracy of class 15: 0.65\n",
      "I\n",
      "Accuracy of class 18: 0.60\n",
      "L\n",
      "Accuracy of class 21: 0.56\n",
      "O\n",
      "Accuracy of class 24: 0.64\n",
      "f\n",
      "Accuracy of class 40: 0.56\n",
      "g\n",
      "Accuracy of class 41: 0.65\n",
      "q\n",
      "Accuracy of class 44: 0.59\n"
     ]
    }
   ],
   "source": [
    "# Вывод результатов по каждому классу с accuracy < 0.87\n",
    "print(\"Classes with accuracy < 0.87:\")\n",
    "for i in range(47):\n",
    "    if class_total[i] > 0:  # Избегаем деления на ноль\n",
    "        accuracy = class_correct[i] / class_total[i]\n",
    "        if accuracy < 0.87:  # Проверяем условие на точность\n",
    "            print(label_dict[i])  # Выводим метку класса\n",
    "            print(f'Accuracy of class {i}: {accuracy:.2f}')\n",
    "    else:\n",
    "        print(f'Class {i} has no samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nSVg_xcbiYdB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1736094770081,
     "user": {
      "displayName": "Leonard Stuchilin",
      "userId": "12835425704178441738"
     },
     "user_tz": -120
    },
    "id": "nSVg_xcbiYdB",
    "outputId": "c4d89540-b742-4de9-a04c-75de4e4d8bdd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W107 10:55:10.689273856 NNPACK.cpp:61] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNModel                                 [1, 47]                   --\n",
       "├─Conv2d: 1-1                            [1, 32, 28, 28]           320\n",
       "├─BatchNorm2d: 1-2                       [1, 32, 28, 28]           64\n",
       "├─MaxPool2d: 1-3                         [1, 32, 14, 14]           --\n",
       "├─Conv2d: 1-4                            [1, 64, 14, 14]           18,496\n",
       "├─BatchNorm2d: 1-5                       [1, 64, 14, 14]           128\n",
       "├─MaxPool2d: 1-6                         [1, 64, 7, 7]             --\n",
       "├─Linear: 1-7                            [1, 128]                  401,536\n",
       "├─Linear: 1-8                            [1, 47]                   6,063\n",
       "==========================================================================================\n",
       "Total params: 426,607\n",
       "Trainable params: 426,607\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 4.28\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.60\n",
       "Params size (MB): 1.71\n",
       "Estimated Total Size (MB): 2.31\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывод информации о модели\n",
    "summary(model_cnn, input_size=(1, 1, 28, 28))  # Указываем размер входного тензора [batch_size, channels, height, width]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56388cb2",
   "metadata": {},
   "source": [
    "## Оценка модели на разных типах данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135dfa6",
   "metadata": {},
   "source": [
    "### Отражение и поворот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96b8b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение трансформаций для нормализации данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Нормализация по среднему и стандартному отклонению\n",
    "])\n",
    "\n",
    "# Загрузка обучающего набора данных с трансформациями\n",
    "train_data = EMNIST('data_c/', 'balanced', train=True, download=True,\n",
    "                transform=torchvision.transforms.Compose([ # Поворот и отражение\n",
    "                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))\n",
    "\n",
    "\n",
    "# Загрузка тестового набора данных с трансформациями\n",
    "test_data = EMNIST('data_c/', 'balanced', train=False,\n",
    "                transform=torchvision.transforms.Compose([ # Поворот и отражение\n",
    "                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63614d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict(image):\n",
    "    # Применяем преобразования к изображению, если они требуются\n",
    "    # image = transform(input_image)  # Примените необходимые преобразования\n",
    "    # Убедитесь, что изображение имеет форму (1, 1, H, W) для модели\n",
    "    if image.dim() == 2:  # Если изображение 2D (H, W)\n",
    "        image = image.unsqueeze(0)  # Добавляем размер канала\n",
    "    image = image.unsqueeze(0)  # Добавляем размер батча\n",
    "\n",
    "    #print('image shape:', image.shape)\n",
    "\n",
    "    with torch.no_grad():  # Отключаем градиенты для повышения производительности\n",
    "        output = model_cnn(image)  # Получаем выход модели\n",
    "        _, predicted_class = torch.max(output.data, 1)  # Находим класс с максимальной вероятностью\n",
    "        predicted_label = predicted_class.item()  # Получаем метку класса как целое число\n",
    "        #print('predicted_label:', predicted_label)\n",
    "\n",
    "        pred = label_dict[predicted_label]  # Получаем предсказанную метку\n",
    "        #print('predicted symbol:', pred)\n",
    "\n",
    "    return pred\n",
    "\n",
    "# Проверяем предсказания\n",
    "fig, axs = plt.subplots(1, 10, figsize=(20, 5))\n",
    "for i in range(10):\n",
    "    random_index = np.random.randint(0, len(train_data))\n",
    "    #print('Random index:', random_index)\n",
    "    image, label = train_data[random_index]\n",
    "\n",
    "    # Преобразование изображения в NumPy массив для корректного отображения\n",
    "    image_np = image.squeeze(0).numpy()  # Убираем размер канала и преобразуем в NumPy массив\n",
    "\n",
    "    pred = predict(image)  # Предсказание для изображения\n",
    "\n",
    "    # Отображаем изображение\n",
    "    axs[i].imshow(image_np, cmap='gray')  # Используем cmap='gray' для черно-белых изображений\n",
    "    # Добавляем отображение истинной метки и предсказанного значения\n",
    "    axs[i].set_title(f'True: {label_dict[label]}\\nPred: {pred}')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdf94d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Устанавливаем модель в режим оценки\n",
    "    criterion = nn.CrossEntropyLoss()  # Функция потерь\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    class_correct = [0] * 47  # Для каждого из 47 классов\n",
    "    class_total = [0] * 47\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)  # Получаем предсказания от модели\n",
    "            \n",
    "            # Вычисление потерь\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Получение предсказаний\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "            # Подсчет правильных предсказаний для каждого класса\n",
    "            for i in range(len(target)):\n",
    "                label = target[i].item()  # Получаем метку класса\n",
    "                class_correct[label] += (pred[i] == label).item()  # Увеличиваем счетчик для правильного предсказания\n",
    "                class_total[label] += 1  # Увеличиваем общее количество примеров для данного класса\n",
    "\n",
    "    # Вычисляем общую точность и среднюю потерю\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "\n",
    "    print(f'Overall Accuracy: {accuracy:.4f}')\n",
    "    print(f'Average Loss: {average_loss:.4f}')\n",
    "\n",
    "    # Вывод результатов по каждому классу\n",
    "    for i in range(47):\n",
    "        if class_total[i] > 0:  # Избегаем деления на ноль\n",
    "            class_accuracy = class_correct[i] / class_total[i]\n",
    "            #print(f'Accuracy of class {i}: {class_accuracy:.2f}')\n",
    "        else:\n",
    "            print(f'Class {i} has no samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5db6119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.7936\n",
      "Average Loss: 2.1104\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_cnn, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051d07a",
   "metadata": {},
   "source": [
    "### Отражение, поворот, дилатация, эррозия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2063934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Для обработки изображений х EMNIST с использованием методов Eroding, Dilating и Smoothing Images, \n",
    " создадим функцию, для предобработки перед передачей изображений в модель'''\n",
    "\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Преобразуем изображение PIL в массив NumPy\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Применяем сглаживание (Gaussian Blur)\n",
    "    img_blurred = cv2.GaussianBlur(img_np, (5, 5), 0)\n",
    "\n",
    "    # Применяем эрозию\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_eroded = cv2.erode(img_blurred, kernel, iterations=1)\n",
    "\n",
    "    # Применяем дилатацию\n",
    "    img_dilated = cv2.dilate(img_eroded, kernel, iterations=1)\n",
    "\n",
    "    # Преобразуем обратно в PIL\n",
    "    img_processed = Image.fromarray(img_dilated)\n",
    "\n",
    "    return img_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29d29c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# использованием методов Eroding, Dilating и Smoothing Images\n",
    "# Загрузка обучающего набора данных с трансформациями\n",
    "train_data = EMNIST('data_e_r/', 'balanced', train=True, download=True,\n",
    "                transform=torchvision.transforms.Compose([ \n",
    "                    # Применяем обработку изображения\n",
    "                    preprocess_image,\n",
    "                    # Поворот и отражение\n",
    "                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))\n",
    "\n",
    "# использованием методов Eroding, Dilating и Smoothing Images\n",
    "# Загрузка тестового набора данных с трансформациями\n",
    "test_data = EMNIST('data_e_r/', 'balanced', train=False,\n",
    "                transform=torchvision.transforms.Compose([ \n",
    "                    # Применяем обработку изображения\n",
    "                    preprocess_image,\n",
    "                    # Поворот и отражение\n",
    "                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a18aa424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiEAAADCCAYAAAAvgWEAAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARIhJREFUeJzt3Xl0FWWe//FvIGQjJEBIIGxJCAKyIyIiHREFFWQUl2PjjNOoraLT7Xacdlp/tsvI0RYZlxkdt3Y/tI7abq2IgivaKiD7KoSEsIR9CUnYub8/PNBdz/OFVIpb91bd+36dwx/1zZN76ybfPFV1i/t8UiKRSEQAAAAAAAAAAACirEm8dwAAAAAAAAAAACQmbkIAAAAAAAAAAABfcBMCAAAAAAAAAAD4gpsQAAAAAAAAAADAF9yEAAAAAAAAAAAAvuAmBAAAAAAAAAAA8AU3IQAAAAAAAAAAgC+4CQEAAAAAAAAAAHzBTQgAAAAAAAAAAOALbkIAAAAAAAAAAABfhPomREpKiqt/X375Zbx31eGqq65ytd9XXXVVvHcVDQhrDx6RkpIiv/3tb+O9G2hAmPussrJSUlJSZPLkyerXJ0+eLCkpKVJZWRnbHUODwtx3IiK1tbVy7733Su/evaV58+aSl5cn/fv3l1tuuUU2bNgQ793DMYS179544w1JSUmRZ599Vv36jTfeKM2aNZMFCxbEeM/QGGHtvyM4rwsn+g6xkKh99uCDD0pKSopcc801cvjw4TjsGY4n7H33j8rLyyUjI0NSUlJkzpw58d4dHEfY++5Y+9uuXbt479oJS433DpyI1157zbH96quvyvTp0636ySefHMvdatCECRNkxIgRR7crKirknnvukeuvv17KysqO1ktLS+Oxe2iEsPYgwoU+QzyEue8OHDggZ555pixfvlzGjx8vN910k9TW1sqSJUvkz3/+s1x88cXSvn37eO8mFGHtu3Hjxskrr7wiv//972Xs2LHStm3bo1+bNWuWPPfcc3L77bdLv3794riXaEhY+w/hRt8hFhKxz/74xz/K//t//0/Gjx8vf/rTn6RJk1D/H9uElEh9d9ttt0lqaqrs27cv3ruCBiRC340cOVJ+9atfOWqZmZlx2psoiiSQ3/zmNxE3L6muri4Ge+Pe7NmzIyISeemll+K9KzhBYetBEYn85je/ifduoJHC1GcVFRUREYk88sgj6tcfeeSRiIhEKioqYrtjaLQw9d2bb74ZEZHIlClTrK/t2bMnsmvXrjjsFbwIU99VVFREsrKyIldcccXR2sGDByP9+/ePFBcXB2If0Thh6r9IhPO6REHfIRbC3meTJk2KiEjkV7/6VeTQoUNx3DM0Rtj67ohp06ZF0tLSInfffXdERCKzZ8+O9y6hEcLWd4l8XE34W8VnnXWW9O7dW3788Uc588wzJSsrS+666y4R+fkjLvfdd5/1PcXFxdZSSDt37pRbb71VOnXqJOnp6dK1a1d5+OGHrY/8VVdXy/Lly+XAgQN+vSSEDD2IWKDPEA9B7bvy8nIRERk6dKj1tYyMDMnJyWnEq0TQBLXviouL5b777pPXX39dpk+fLiIi//3f/y3z58+Xp59+WrKysry/aARGUPsPiY2+QyyEpc8effRRueOOO+TKK6+Ul156iU9AhFzQ++7AgQNyyy23yC233MJqJQkk6H2XqEK9HJNb27Ztk1GjRsm4cePkyiuvdHxE3o36+noZNmyYrF+/XiZMmCCdO3eWv/3tb3LnnXdKdXW1PP7440fH3nnnnfLKK69IRUWFFBcXR/eFILToQcQCfYZ4CGLfFRUVicjPH729++67JSUlxctLQ4AFse9Efv6o/pQpU+TGG2+UadOmyT333CPjxo2T888/38OrRFAFtf+Q2Og7xELQ++yJJ56Q22+/Xf75n/9ZXn75ZW5AJIgg993jjz8uO3bskLvvvlveeeedRr4yBFmQ+27v3r2ydetWR61FixaSnp7eqH0MmqS4CbFx40Z55plnZMKECZ6+/9FHH5Xy8nKZN2+enHTSSSLyc65D+/bt5ZFHHpHbb79dOnXqFM1dRoKhBxEL9BniIYh9N3bsWOnevbvcc8898sILL8jw4cOlrKxMxowZIwUFBZ72E8ESxL4TEUlNTZXnnntOhgwZIoMHD5bU1FTHBQgSQ1D7D4mNvkMsBLnPPvzwQ1mzZo1cccUV8uqrr0rTpk09PQ6CJ6h9t3HjRnnggQdk8uTJfJI6AQW170REXnjhBXnhhRcctZdeesn6JEbYJMVt4/T0dLn66qs9f/9bb70lZWVl0qpVK9m6devRfyNGjJBDhw7J119/fXTsyy+/LJFIhP8xAgd6ELFAnyEegth3mZmZ8sMPP8jvfve7o9/361//WgoLC+Wmm24iUC4BBLHvjjjttNPkhhtukO3bt8tDDz3U6P9VheALcv8hcdF3iIUg99mmTZtERKSkpIQbEAkmqH33H//xH9KlSxe59tprPe8bgiuofScictFFF8n06dMd/8477zzP+xoUSfFJiA4dOkhaWprn71+5cqUsXLhQ8vPz1a9v3rzZ82MjOdCDiIUw9xnL5YRXUPsuNzdXJk2aJJMmTZI1a9bIZ599JpMnT5Ynn3xScnNzZeLEiZ73GfEX1L47YtCgQSIicuqpp57Q4yCYgt5/SEz0HWIhyH02fvx42bBhgzz44IPSpk0bue222zw/FoIliH33/fffy2uvvSafffYZy34lqCD23REdO3aUESNGeP7+oEqKmxCZmZmNGn/o0CHH9uHDh2XkyJFyxx13qOO7devmed+QHOhBxEIQ+ywjI0NERPbs2aN+vb6+3jEO4RPEvjMVFRXJNddcIxdffLF06dJFpkyZwk2IkAtD3yFx0X+IB/oOsRDkPktNTZU333xTzj//fLn99tulZcuWJ/S/mBEcQey7O+64Q8rKyqSkpEQqKytFRI6u0V9dXS1VVVXSuXPnRj8ugiOIfZfokuImxLG0atVKdu7c6ajt379fqqurHbXS0lKpra1NyLtQiC96ELEQzz7Lz8+XrKwsWbFihfr1FStWSFZWlrRp0yZqz4lgCOL81qpVKyktLZXFixf7/lyIjyD2HZIH/Yd4oO8QC0Hps4yMDPnggw9k+PDhct1110nLli3l4osv9uW5EH/x7LuqqipZs2aNlJSUWF+78MILJTc319o3JIagzHeJKKk/U1RaWupYo0tE5LnnnrPubl1++eXy3XffySeffGI9xs6dO+XgwYNHt6urq2X58uVy4MABf3YaCYUeRCzEs8+aNm0q5557rvz1r3+Vqqoqx9eqqqrkr3/9q5x77rms65qA4tl3CxYsOPo/lf7RmjVrZOnSpdK9e/fGvBSECMdVxBP9h3ig7xALQeqznJwcmTZtmnTt2lWuuOIK+eyzzxr1/QiPePbdc889J++++67j30033SQiIpMnT5YpU6Z4fVkIuCDNd4kmqT8Jce2118oNN9wgl156qYwcOVIWLFggn3zyifU/cn/3u9/JBx98IGPGjJGrrrpKBg4cKHV1dbJo0SJ5++23pbKy8uj33HnnnfLKK69IRUUFQV5oED2IWIh3nz344INy+umnyymnnCLXX3+9FBcXS2VlpTz33HOSkpIiDz74oF8vHXEUz76bPn263HvvvXLhhRfK6aefLtnZ2bJ69Wp58cUXZd++fXLffff5+MoRT/Ge75Dc6D/EA32HWAhan+Xn58v06dNl6NChMnbsWPnss8/ktNNOi9bLRUDEs+/OPfdcq3bkf8cPGzaM3K8EFrT5LpEk9U2I6667TioqKuSFF16QadOmSVlZmUyfPl3OOeccx7isrCz56quv5MEHH5S33npLXn31VcnJyZFu3brJ/fffL7m5uXF6BQi7ePZgJBIREeF/oCeBeM91J598svzwww9y3333yQsvvCDbt2+X1q1by8iRI+Xee++VHj16RONlImDi2XeXXnqp7N69Wz799FP5/PPPZfv27dKqVSs57bTT5Pbbb5fhw4dH62UiYOI93yG50X+IB64nEAtBnN86deokn376qZSVlcmoUaPk66+/ll69ekXt8RF/Qew7JD76zj8pkSNnDgCSSk1NjeTm5srdd98tDzzwQLx3BwAAAECIcD0BAADcSupMCCCZzZ49W0REevbsGec9AQAAABA2XE8AAAC3+CQEkGQWLlwoM2bMkEcffVT27t0rq1evlpycnHjvFgAAAIAQ4HoCAAA0Fp+EAJLMO++8I3fddZcUFxfLxx9/zAUDAAAAANe4ngAAAI3FJyEAAAAAAAAAAIAv+CQEAAAAAAAAAADwBTchAAAAAAAAAACAL7gJcYKKi4vlqquuivduIInRg4gF+gzxQN8hHug7xAN9h3ii/xAr9BpijZ5DvNB7tlDfhHj55ZclJSXl6L+MjAzp1q2b/Pa3v5VNmzbFe/eOq7i42LHvx/r38ssvx3tXcRxh7kERkS+//FJSUlLk7bffjveu4DjC3mdH9n/OnDnq18eMGSPFxcWx3Sk0KOx9JyJSWVkpV199tZSWlkpGRoa0a9dOzjzzTLn33nvjvWs4hjD33Q033CBpaWmyePFi62sHDx6Uvn37SnFxsdTV1cVh73A8Ye47Ec7nwo7+Q6wkaq/t379fxowZI02aNJEXX3wxTnsHTdh7zjRlyhRJSUmR7OzseO8KGhD23jsy32n/xo0bF+/d8yw13jsQDf/5n/8pJSUlsnfvXvnmm2/k6aeflqlTp8rixYslKysr3runevzxx6W2tvbo9tSpU+X111+Xxx57TNq0aXO0fsYZZ8Rj99BIYexBhA99hngIa9+tWrVKBg0aJJmZmXLNNddIcXGxVFdXy9y5c+Xhhx+W+++/P967iOMIY9/98Y9/lPfff19uuOEGmTlzpqSkpBz92mOPPSaLFi2Sjz76SJo3bx7HvcTxhLHvkDjoP8RKIvXagQMH5LLLLpOpU6fK888/L9dcc028dwmKROi52tpaueOOOziPC5mw997NN98sgwYNctTC/B84E+ImxKhRo+TUU08VEZFrr71W8vLy5NFHH5X3339frrjiCvV76urq4jp5jB071rG9ceNGef3112Xs2LGhbqhkFcYeRPjQZ4iHsPbdY489JrW1tTJ//nwpKipyfG3z5s1x2iu4Fca+a9mypTzxxBPyy1/+Up5//nm5/vrrRUSkqqpK7r//frn88stl9OjRcds/NCyMfYfEQf8hVhKl1w4cOCCXX365fPjhh/Lss8/Kr3/963jvEo4hEXpu4sSJ0qJFCxk+fLi899578d4duBT23isrK5PLLrss3rsRNaFejulYzj77bBERqaioEBGRq666SrKzs6W8vFxGjx4tLVq0kH/5l38REZHDhw/L448/Lr169ZKMjAxp27atTJgwQXbs2OF4zEgkIhMnTpSOHTtKVlaWDB8+XJYsWaI+f3l5uZSXl/v4ChF09CBigT5DPISl78rLy6Vjx47WDQgRkYKCgka9ZsRfWPruyI2G3//+90dvdt10003SrFkzeeKJJzy/fsRHWPoOiYn+Q6yEsdcOHjwo48aNk/fff1+efvppue666xr7shFHYeu5lStXymOPPSaPPvqopKYmxP/lTlph671Ek5B/PUd+oXl5eUdrBw8elPPOO09+8YtfyOTJk49+7GbChAny8ssvy9VXXy0333yzVFRUyJNPPinz5s2Tb7/9Vpo1ayYiIvfcc49MnDhRRo8eLaNHj5a5c+fKueeeK/v377ee/5xzzhGRn9eiRnKiBxEL9BniISx9V1RUJDNmzJDPP//86MkmwissfSci8r//+7/Sq1cvue222+Tyyy+XDz74QJ555hlp167dif4YEGNh6jskHvoPsRK2Xjt48KBcccUV8u6778pTTz0lEyZMOJGXjzgIW8/deuutMnz4cBk9erS8+eabJ/LSEWdh673du3fL1q1bHbXWrVtLkyYh/UxBJMReeumliIhEZsyYEdmyZUtk7dq1kTfeeCOSl5cXyczMjKxbty4SiUQi48ePj4hI5Pe//73j+2fOnBkRkciUKVMc9WnTpjnqmzdvjqSlpUUuuOCCyOHDh4+Ou+uuuyIiEhk/frzj+4uKiiJFRUWNei2PPPJIREQiFRUVjfo+xFfYe/CLL76IiEjkrbfe8vDqESth77Mj+z979mz16xdccEGj50z4L+x9t3jx4khmZmZERCL9+/eP3HLLLZH33nsvUldX5+GngVgJe98dMXny5IiIRFq3bh0ZOnSo4zkQPGHvO87nwo3+Q6wkSq8VFRVFRCTy1FNPefgpIJbC3nORSCTy4YcfRlJTUyNLliw5uq/NmzdvzI8BcRD23jsy32n/wvy+cUhvnTiNGDFC8vPzpVOnTjJu3DjJzs6Wd999Vzp06OAYd+ONNzq233rrLcnNzZWRI0fK1q1bj/4bOHCgZGdnyxdffCEiIjNmzJD9+/fLTTfd5AgZvPXWW9X9qays5H+MJBl6ELFAnyEewtp3vXr1kvnz58uVV14plZWV8sQTT8jYsWOlbdu28vzzzzfuh4CYC2vf/ePj9O3bV3bu3CnPPvus4zkQXGHvO4Qb/YdYCXuvbdq0SVJTU6WkpMT19yC+wtpz+/fvl9tuu01uuOEG6dmzZ+NeNAIhrL13xD333CPTp093/Avzp6sTYjmmp556Srp16yapqanStm1b6d69u/XRlNTUVOnYsaOjtnLlStm1a9cx14Y+spbvmjVrRETkpJNOcnw9Pz9fWrVqFa2XgRCjBxELidxnvEEXXGHuu27duslrr70mhw4dkqVLl8qHH34okyZNkuuvv15KSkpkxIgRJ/T48E+Y+05EpGnTpjJgwAApLy+XXr16nfDjITbC3ncIN/oPsRL2Xps0aZI8/vjjctlll8mnn34qQ4cOPeHHhL/C2nOPPfaYbN26Ve6//37Pj4H4CmvvHdGnT5+EumZNiJsQp5122tG082NJT0+3Gu3w4cNSUFAgU6ZMUb8nPz8/avuIxEYPIhbC2mcZGRkiIrJnzx716/X19UfHIHjC2nf/qGnTptKnTx/p06ePDBkyRIYPHy5TpkxJqBO6RJMIfYfwoe8QT/QfYiXsvVZYWCjTp0+XX/ziF3LBBRfIV199Jf369YvJc8ObMPbcrl27ZOLEifJv//ZvUlNTIzU1NSIiUltbK5FIRCorKyUrK+uYb1IjGMLYe4ksIW5CeFVaWiozZsyQoUOHSmZm5jHHFRUVicjPd8K6dOlytL5lyxYrFR1oDHoQsRDvPjvyuCtWrJCysjLr6z/99JP07t3b8+MjmOLdd8dy5CS0uro66o+N+Atq3yGx0XeIJ/oPsRKkXuvSpYt88sknMmzYMDnvvPNk5syZ1v9ERvjFs+d27NghtbW1MmnSJJk0aZL19ZKSErnooovkvffe8/T4CLYgzXeJJCEyIby6/PLL5dChQ/LAAw9YXzt48KDs3LlTRH5eQ6xZs2byP//zPxKJRI6Oefzxx9XHLS8vP5q4DhwPPYhYiHefDRw4UAoKCuRPf/qT7Nu3z/G19957T9avXy+jRo1y/4IQCvHuu5kzZ8qBAwes+tSpU0VEpHv37i5eBcIm3n2H5ETfIZ7oP8RK0HqtT58+8tFHH0ltba2MHDlS1q9f3+jHQLDFs+cKCgrk3Xfftf4NHz5cMjIy5N1335U777zT82tDsAVtvksUSf1JiGHDhsmECRPkoYcekvnz58u5554rzZo1k5UrV8pbb70lTzzxhFx22WWSn58v//7v/y4PPfSQjBkzRkaPHi3z5s2Tjz/+WNq0aWM97jnnnCMiQpAXGkQPIhbi3WdpaWkyefJkGT9+vAwaNEh++ctfSl5ensybN09efPFF6du3r1x//fV+vHTEUbz77uGHH5Yff/xRLrnkEunbt6+IiMydO1deffVVad269THDwhBu8e47JKeg9N1f/vIXWb58uVUfP368dOrU6YReI4IrKP2HxBfEXhsyZIi888478k//9E8ycuRImTlzpuTl5Z3oS0VAxLPnsrKyZOzYsVb9vffek1mzZqlfQ+II4nyXCJL6JoSIyDPPPCMDBw6UZ599Vu666y5JTU2V4uJiufLKKx0BRxMnTpSMjAx55pln5IsvvpDBgwfLp59+KhdccEEc9x6JIJ49eORObdOmTU/4dSDY4j3X/eu//qvk5+cf/Tjrnj17pGPHjnLzzTfLH/7wh+N+xBHhFc++u+uuu+TPf/6zfPXVVzJlyhSpr6+XwsJCGTdunPzhD3+QkpKSaLxEBFC85zskpyD03RtvvKHWzzrrLG5CJDiuJxArQZjrTOeee6689tprcsUVV8ioUaPks88+kxYtWkT9eRAfQew5JAd6L/pSIv/4eREASeWDDz6Qiy66SGbMmHH0jiwAAAAAuMH1BAAAcCOpMyGAZDd79mwREenZs2ec9wQAAABA2HA9AQAA3Ej65ZiAZPTpp5/KV199Jf/1X/8lI0eOlMLCwnjvEgAAAICQ4HoCAAA0BssxAUlo+PDhMnfuXDnvvPPkySeflIKCgnjvEgAAAICQ4HoCAAA0BjchAAAAAAAAAACAL8iEAAAAAAAAAAAAvuAmBAAAAAAAAAAA8AU3IQAAAAAAAAAAgC9S3Q5MSUnxcz8QMrGKEolm3zVpYt9zy8jIcGw3a9bM02MfOHDAqh06dMjTY0XT4cOHPX2f9vvVHsvr43sVi75jrsM/CuNcF1RuXqPXn4P2ewpz5BV9l9iaNm1q1Vq0aGHV0tPTPT3+9u3brZp2nmLiGItYY65DPAR5rtOuV1NTXb9l06CDBw86tmN9LZesmOviz/zZmO8DiYhkZmZ6euy6ujqrtn//fqsW62sT+i54tJ9VWlqaVdN6MScnp8ExbuzcudNVzWsPNzSGT0IAAAAAAAAAAABfcBMCAAAAAAAAAAD4gpsQAAAAAAAAAADAF9FbYBAIEG2tNW3dv9atWzu2CwoKPD1ffX29VdPWUAtChoJWM/MrtH3fs2ePVdu7d+9xH+dYzwcgsWlzsLnOsbbGsbYWshvaevdusm2YnxALZgZE8+bNrTGdO3f29Nja8bqmpsaqucmEQLBEc41l5jpEm9afZs3NucCJMPMNRMLf69rPJzs729U4N3bt2uXYTrRMLYSDNjdoeVluuM2yNLM/W7ZsaY1p27atp31Yu3atVdPW2A9CZihiy+w7LcdB68XCwkKrZl4rmBkRbi1btsyqrVy50qppGXPR6GE+CQEAAAAAAAAAAHzBTQgAAAAAAAAAAOALbkIAAAAAAAAAAABfkAmBhKStKWjmP4iInHrqqY7t008/3dPzaWstm3kJIrFfB1B7Pm39VHNftTUMKyoqGqxp68axDjWQOLQ1iM21LkX0DJ6srCzHdosWLawxWk6EG3V1dVZNy+ox5zot64ZsG5wI7fwjNzfXsd2zZ88Gx7hVXl7u6fsQPG5yc7zSzv1inVOW7LxmJWlzSjTzQtzQnk879qenpzu209LSrDHaethuaMdr7brDPPYHuc/dZhh26tTJqmk5EW6sWLHCsb1jxw5rDOvWI9rMecy8JhARyc/P9/TY2vsWtbW1Vs287ujdu7c1xnxvyK2PP/7YqmnXIdo8hnDSjoHa8c3MnC0tLbXGaL3Yv39/q6ZlR7ixadMmx7a279rf0e7du60amRAAAAAAAAAAACCwuAkBAAAAAAAAAAB8wU0IAAAAAAAAAADgC25CAAAAAAAAAAAAXxBMjaShBaqaoV7FxcXWmEGDBlm1vLw8x3asA+Lc0sJU9+/fb9XM4KS1a9daY77++murZoYwLVmyxBqjhdwQ8vp3Wu+4rbmh/azNGr8PHIsZkqkFIZqBWyIi7du3t2qFhYWO7bZt21pjtEBGN7Rgxc2bN1u19evXO7Y3bNhgjdHmLDNITgu6TPa/I22OilawrhaqG4Sft/aamzdvbtXMIOqSkhJPz6eFsCL43P5tmIGGOTk5np/TDA7ctWuXNWbv3r1WLcghvmGi/c61kGYzkF47nmrHXe2x/KSFY5shryIirVq1anCM12DN8vJyqzZv3jyrZl7DJEIQrNZPXgN0zaBRt+G5QTjmIrzM0HrtPOj000/39Njff/+9VauqqrJq5nXHkCFDrDHa+z5uzJkzx6qtWrXK02Mh/rQ51+xh7Xhtnu+L2H3Wt2/fE9y78OOTEAAAAAAAAAAAwBfchAAAAAAAAAAAAL7gJgQAAAAAAAAAAPAFNyEAAAAAAAAAAIAvohpM7XeY6omMAxB9ZricFshpBqCJ6CGjycIMSG/WrJk1Rgvn9RpCqAVPmoFzZoClCHNrMjJ7U8QOxOzatas1Rgtx69evn1UzQ+jMoGoR78HUWpi0Fjq9dOlSx/bcuXMbHCNiB1rX1tZaY7S/o2SiBe22adPGsW2GurlVXV1t1fbt2+fpsaJJ69fi4mKrNnjwYE+Pr4Wrm7Zt22bV9u/f7+n5EB3mtY/2t6GFTnfs2NGxfdJJJ3neB3NOXLlypTVG6y/znIFzAXfM37l2zqaFWPbu3duxPXDgQGuM2Rci3o+VXmnB1GaotohIXl6eY9truPqBAwes2vz5862ado5r9r72WMmsc+fOjm3z/EZE/7kyF8Atbb4wQ+u1ua5Pnz6enu/HH3+0atp7EuZ1h7YPSD7aezFa/5hzpxZsPnLkyOjtWALjkxAAAAAAAAAAAMAX3IQAAAAAAAAAAAC+4CYEAAAAAAAAAADwBTchAAAAAAAAAACAL1wHU2uBlWbQmhbg4TU4Swuu1UIIzXGHDx+2xrgNXTVDxbyGamv7rj0fAU9AYtPmEDOs0AzqEhEpKiqyalqgoRtVVVVWbe3atY5tLdQ32UN2k5EWnmqGTPbv398aM2rUKKumhXW5sWPHDk/f17JlS1e1nj17Ora1cGwtoMwM+tWCf5M9yFHrHzPErVOnTp4ee+bMmVZNC9X18+etBS22bt3aqp122mm+7YMWzLp9+3arxvwdX+axPzMz0xrToUMHq2YGmA8dOtTzPixZssSxvXv3bmvMrl27rJp5rZVMc9iJMH/nLVq0sMZ0797dqp1//vmO7bPPPtsa06ZNG6umzT1aGLYbP/30k2N73rx51hjCnWPH7/nbnHu0XtXmBu09FkCTnp5u1cy+O+OMMzw/vna+bdLO5c1z0Pbt23veh40bN3r+XsSOeWzWelN7j6VXr15Wbfjw4dHbMY++/PJLx/aKFSusMdr7OuYxXJvjN23a1OD3RQufhAAAAAAAAAAAAL7gJgQAAAAAAAAAAPAFNyEAAAAAAAAAAIAvXGdCaNkO5nrL2lqX2trmbmj5D9r6VuYap7W1tdYYbd04LbfBXM9YW9/YjZqaGlf7oK2xZe6X2zwLN+tHuv0+c1wY14PVXte2bdus2qxZsxzbWo999dVXVi0nJ8ex7TU/RKOtYdiuXTurduaZZzq2zbXbG2PVqlWObW1NONaYbjxtDXEzO6ekpMQao60Drc2vbnzzzTdWzZwntXkzmr9v7e/DrHmdbzXk8nijZT+ZawV36dLFGtOvXz+r5nVt6ljr06ePVVu2bJlVW7p0qWNb+9tGw7S1WN3o2rWrVaurq3NV8/p3bs5Rubm51hhtzdho+u677xzbW7dutcZwbA4eN/kA2lxqZkJo+QBumdci2j5ox91ons8COD7t+KS9P6Bdn5rZVFp2iMa8hs3OzrbGaHODdm4NaMcMLSfWPOZpGXNuff/99w2O0fZBu+b2atGiRY7t9evXW2O0/Dj4R+tFM5PLzKoTESkrK7Nql1xyiad90K5DTNp5u5Z9t3DhQqtWUVHh2NZy4dz0nXbs0eZ4v64x+CQEAAAAAAAAAADwBTchAAAAAAAAAACAL7gJAQAAAAAAAAAAfMFNCAAAAAAAAAAA4AvXSaBaaJEZ7DFy5EhrjBb04TXQUQsWNoOaduzYYY3ZtWuXVdNCn8zARK9BqZs3b3a1D1oYrDluz5491pj6+nqrZgaQaMEiWji2tl9m2HcYQ3W0sBXtZ1lVVeXY1kIfs7KyrJrZw9EM8tNC4LXwy7Zt23p6fO1v5PPPP3dsV1dXW2O0UDTz56U9drKEZmo9oIWMt2rVyrF90kknWWNOP/10q9atWzdP+7VhwwarNn/+fMe2Fkjsldufg3lMadmypafn0+Y6rVe1oKhk6c0w2bdvn1Uzj/1aQLAWQIdw6NSpk6cx2vF69erVVk073zO5CVb0OgeL6OdaJnNeFrHnb+3vA8FjXj9oodBaQGbv3r192yfgRKxbt86qLViwwKpp11peHD582Kpt3LjRqq1cubLBfdCuCYNMe+3a3G++j9C1a1dPz6e9xxPN6wIkNq1XtHPy4uLiqD1neXm5Y1u7xissLLRqPXv2jNo+mPPfli1brDFuzj/hjdtAdPP96hEjRlhjotmb2nWI+f7Yt99+6+r7tNBp81igHS/CcMzjCAMAAAAAAAAAAHzBTQgAAAAAAAAAAOALbkIAAAAAAAAAAABfcBMCAAAAAAAAAAD4wlvycoD17dvXqp1yyimuvtcMpnbLDMPRwhK1EGotKNoMLtECVrWa+fhaMNimTZus2vLlyxusac8XRlpwi/k70IK//H79ZqBTTk6ONUYLG0tLS/P0fIsWLbJqs2bNcmxrvaIFAJvBvtqYMITjRIMWkKSFjBcUFDi2S0tLrTE9evTwtA9aj/vJaxi3iEhRUZFj++STT/a0DzU1NVZt2bJlVm39+vVWzZy7Y/3zg62qqsqqzZ0717GdlZVljTnjjDOsmtaL8M/+/futmvn79BqcqenXr59V086/zGA37ZikzdVmUJ0WJKzRAhLNcPX6+nprzKpVq6xatEJe4R83x8E2bdpYY7p06WLVtPMBN+iT4NECSTdv3mzVvvvuO8e2FgDt9rpg2LBhjdnFo+bPn+/Y/uijj6wxS5cutWra9ZGbIFbtb8YNrc+1+da8tkuEczvt56q9t+BFbm6uVdPeE9F+/kG8xvPaX0F8LWHQtGlTq6bNWe3bt4/ac5rXdFo4tnaM7dOnj6fnM98nERGprKx0bGt/j/RU9Jh/1y1atLDGaL/zkSNH+rZPGjM0XUTkq6++cmxrx3ltfjXfZ0skfBICAAAAAAAAAAD4gpsQAAAAAAAAAADAF9yEAAAAAAAAAAAAvki4TAi3tHXE3NDWPEbi0Nbui/V6fto6nG3btrVqXjMhNm7caNV27drl2NbWWGVdw+PT1qPMzs62ah06dHBsa+uM5+fne9oHLcvDT25fs/YahwwZ4tguKyvztA/mmpwiet6O2eMi+rrsyUxbN3n37t2O7TVr1lhjtPUvBw4c6GkfMjMzrZqZ1WOury8i8tNPP3l6PreZIlu2bHFscy5g09YuNfMYzLXHRUQ6derk6fmaN29u1bS5xlxnVVtbWzvGajkjbph/MxptfXVtjuK4G3xu8qC0Y7qZOSLi/dpEyxowa27X76fnvDGPn9r64KtXr7ZqZo6Ndg6l1bQMRG1tfy/MfEIRkbVr11o1rafM44DWT9Fcsz8I123Rpu2/n5mF2lr9Ws9p50uxXrNc6x3zWsRrHpg2H2rnxWHvr6DQ3o9wy7x+0zIovGYNarTMLvO6wE0eDrwz3/cqLCy0xkQz/0G7FjR9/fXXVk27zjF7XZvPk21e4ZMQAAAAAAAAAADAF9yEAAAAAAAAAAAAvuAmBAAAAAAAAAAA8AU3IQAAAAAAAAAAgC9cB1NrAVtVVVWO7alTp1pjtPC9li1bWjUzAEkLZ9Nq2mMBYdK0aVPHthYs17lz56g9nxaaaYasJls4TmNpwWhaUHheXp5V69Kli2O7W7duUdsvMwRWRA+rNoNateA1jfm6tfC31q1bW7VevXpZtbPOOsuxPWzYMFf7YHr77bc9fR9sBw8etGpmQKUW1PXDDz9YNS3o1w2tf0pLSx3by5cvt8ZoAeVuzJ0716pp5y1mAKT2s2LetJnHFi3cdM6cOVbNDKvWgn212tlnn23VzN+Vdj47aNAgqxZNixYtcmwTQh1O2rHfPIcTsa9ptPnQayC7Zv369VbN/FvTzg/Mv08R+jBatMDeuro6q2aej5lhpyIiWVlZVk075ywvL3dsu53XzOOuNremp6dbNe01xjqoOBFpf4PaOYd5HNHGuFFUVGTVtGtR7XrC6+/bnEvdzq1aH5rvD2khxW5or0+7ZqbH48+8vtbmrFNPPTVqz2e+5yli9wZ94S/zb7979+7WmP79+3t6bC1MWjsWm9cr2rmXdo1hzs2cZ/FJCAAAAAAAAAAA4BNuQgAAAAAAAAAAAF9wEwIAAAAAAAAAAPiCmxAAAAAAAAAAAMAXroOp9+7da9XMwA4tvEcLsdRChcyArYyMDGuMGfQmYgfR9OvXr8HHFhEZMmSIVXPjyy+/tGqzZs1ybGvBRloYmRbqqr1uN8zQTDPoTBsjou+r+bsmaCeYmjTxdg9RC/pyExBGiM7faT8f7W+3oKDAqplB1GborltamPTKlSutmhbY6ybMTnuNZs81b97cGqOFbfbt29eqDRgwwKohvrSeMo9da9asscYsWLDAqml97TWE3ewV7VxD630tVMwMa9Vez7Zt26zavn37HNtuw9yTnXnc0M6FtPNEN6G97du3d7UPV111lWNbOxdyY+PGjVZN6wMt7Hzr1q2Obc6rwkk7LmZmZlo1MzRT6+d27dpFbb+0ecwMTKypqbHGEEwdW9rP1pwLtLmhvr7eqmlB4+bv3G0wtam4uNiqaWG/0QwqxvFp5+lmX2jHNi102qSFUGu11FT7bSNzDnFz7SBivweiXU+Y86iIfl3l5nxBY/bqDz/8YI3RzlnocSftPEjrxYULFzq2S0pKPD/nWWed5djW3iPU3u/QrgtMWrDwhg0brJr5XhvHzujR5hHzGNSrV6+oPZ95ji4i8vnnn1s185jHOZR3fBICAAAAAAAAAAD4gpsQAAAAAAAAAADAF9yEAAAAAAAAAAAAvuAmBAAAAAAAAAAA8IXrYGotdMasHThwwBqjBYtozHFamHSLFi2smptAa813333X4BgtxO3//u//rNqPP/7o2N6xY4c1RguU0gJztNAnN8zQTO35tN+P+X3aOAKYEkvLli2tmvl3owW/ErTzd9q8ps1ZWqia1wA1kxbEu3jxYqtmBvGK2KFb2u9WC5Izg+MKCwutMT179rRqWjB1rBEk7I15PNDC5lavXm3VFi1aZNXMYGrtGOiGFnCt9fm6deusWnl5uWNbO14TNOYf7XxCC4Qzz6vOP/98V49/8cUXW7XOnTu73DuniRMnNjimqqrKqlVXV1s17fwLwaYd580wVRE9wNUM3DzppJOsMW3btvW0X9p8a85rInaQphZuzHExHLR5UwtP3bhxY1SeT+tN7RrcTVAxokP7WzWDcbVrt9atW3t6Pre/b7Pm9v2bNm3aOLa143SPHj2sWteuXe2ddWH58uVWTQtWR+Np89P27dut2pw5cxzbZg8ci3bOP2TIEMe21itufPPNN1bNDNAW0edWzuv8o80jZr9o7zd4pf3OtfnBPL5p14Zu3vvW3mPxSjs2hOGalU9CAAAAAAAAAAAAX3ATAgAAAAAAAAAA+IKbEAAAAAAAAAAAwBfeAggawe2aVOb6Wdq6qx06dLBqgwcPdmwPHDiwEXt3fB999JFV07IkzDWB9+7d6/k5va4RZq4H5vbnHoY1wxKduZaits6rubbviTDXKhax1zTW1nJk7eC/c5sJoa2DqmVyeKGtAb1q1Sqr5mZNQ22d18zMTKvWsWNHx/aAAQOsMaeffrpVc5MJoa0pWldXZ9XMdTmXLFlijdHWadfWyk2mnjZ7VuthN+tYajlC69evt2rz58+3aubcM2jQIGuMlqPiZoyWCbFs2TKrZvaZtqYrx8XY0tYQN/M8tL/z9u3b+7ZPbi1dutSqafMWwkebD9PT061afn6+VevSpYtjW1vT2ivt+KbVzPM4be5mrgsH7fdk5gGIiGzbts2xvXnzZk/Pp63V3qpVK6um/T2Y+0WPRYf2czT/prXrR+06xI2cnByrpuXfmI+vzYfFxcVWzZwTT2R9d4658eV2fqqoqHBsT58+3Rpz2mmnRW/HPDKzK0T0TAgtfxXRob0PbGYVec2HmTt3rlXTrgWzs7Otmvk+rZZtqL0fZL4e7fW5Zb7PrM1/2nse5vEi3sdmPgkBAAAAAAAAAAB8wU0IAAAAAAAAAADgC25CAAAAAAAAAAAAX3ATAgAAAAAAAAAA+ML3YGqNm7C3oqIia8yZZ55p1S655JIGn08LPN25c6dVW7x4sWNbC6HWAjijGcKVTEGp+JnZLzU1NdaY1atXW7Vdu3Z5ej4tyKegoMCxrfW5FtqTLMw5Swsi0oKctUA4M+hIC5JzQwsr37p1q1UzA4xE7P3XAug6depk1cwgam1OHjZsmL2zHmlz6Y8//ujY1oJhtTDGZArlNIOzROwQrIyMDE+Prc0D2lykBaebQdFaMLXXsK4+ffpYNS0c29yHHTt2WGM4DseW9ndohqotWLDAGlNYWGjVLr744ujtmOGbb76xalu2bLFq2jkngs88zqem2pdIzZs3t2pmWKKISGlpqWNbO556VV1dbdW0Y795bcK8Fl7aHKkdi815Uzs2ew1J79ixo1XTznHNaxjmw+hw0wNaGLD2nosbWpi0dj1hXj906dLF0/PFw/Llyx3bZrC7CP3rlfZzM693V6xY0eCYYxkyZIi3HTOY15Qi+n5pcym94R/tWrBVq1aO7fbt23t6bG2e1N7P0AKfzflOOwZq7weZ544nEky9bt06x/aiRYusMQsXLrRq5rljvN/X45MQAAAAAAAAAADAF9yEAAAAAAAAAAAAvuAmBAAAAAAAAAAA8AU3IQAAAAAAAAAAgC/iEkythb21adPGsX3KKadYYy688ELf9klEZNasWY7tNWvWWGO0kJJEDTdFbJj9owXoaiHEZqBW586dPe+DGaxoBsWLiNTX11u1ZOl9M9hN+/mYgUkiduC3iEjLli097cPGjRsd224DdXNzc61aVlaWY1sLzezbt69VGzp0qGNbCxbWwmLd0EK/zDlZq1VWVlpjzHBGkcQN5dRCB7VjrBmm1aFDB0/Pt3PnTqu2fft2q6b9Ps15bNOmTdaYdu3aedovLQyxpKTEquXl5Tm2tZBXLWwuWea6oDh48KBjWwuS00IktVB6rWYyA8tFRKZNm+bY1uYaLagT4WTOpVq4oHZ86969u6uaSZs3TW7PB7V52QwdZA5LLNo5jTkfaeftXo+xWgC7eS4pItK0aVPHNuGt0aH9/Zo9YB43T0RZWZlV6927d4Pfp4Wdau+nRJP5nIsXL7bGzJs3z6qtXbvWsa2dZyTqtUM8mHOB9p7a1q1brZp2rDR/V+Y1sltaCPWWLVus2v79+z09PhpmHjNE9MBn870Kr+97me85i+jndlrfmbWamhprjHbeZtaYV/gkBAAAAAAAAAAA8Ak3IQAAAAAAAAAAgC+4CQEAAAAAAAAAAHzheyZEkyb2fQ5zbWoRkR49eji2hw0b5ts+iYh8/fXXVs1cEziZ1hVHcGjraWprX//000+O7RPJhDDXiNXWedXWHE6WNYbNeSw7O9sao60nWFRUZNXMNendMtcubd68uTWmtLTUqmlr5efn5zu2tbXztXnaT+vWrbNqS5cutWpm32trd2p/Q8nSqyIiaWlpVs3MJ+nfv7+nx66trbVqixYtsmpu1vCvqKiwxvTr18+qaecRbmh9bWZhmH9XIvrar9FcaxkNM3tYm1979epl1bT1hN149913rZqZu0QmWOLQsnTMrCfzOCkicvLJJ1s1LRvJa/aTaeHChVZt1apVVk3LiGLOSj7mfEQPJDbz9+32PYozzzzT0/Np53XffvutY1s7J3ejvLzcqmmZXW5yn7Qx2rmBeUwnvyS2tHN77drWTY6N1isaMztC6zvtOodzPf80a9bMqrVv396qaXnBCC8+CQEAAAAAAAAAAHzBTQgAAAAAAAAAAOALbkIAAAAAAAAAAABfcBMCAAAAAAAAAAD4IqrB1FrQW0ZGhlXTwlrLyso8Pee+ffsaHDNr1iyr9t1331k1M6xGC6dEYtNCkrTAHDe0cFw3oWFa+JEWkqSFunrVsWNHx3Zubq41ZtOmTVaNoPbYadOmjWO7b9++1hgtiNcNLdQy1rQe12p79+51bGvBi8kUIKYdd7V5rEWLFo7tHj16WGPM8Gq3tCA5M9RXxP59LlmyxBqjBal7DdE+6aSTrFq3bt0c2ytXrrTG7N6926qZAYbJ1GN+03rYDPYdMGCAq8cyQzI1Wmjljz/+aNVqamoc2/zOE4fWc5mZmY5t7VpFC6EeMmRIg8+3a9cuq2b2l4g9z3z//ffWGG1uJZg6sWn9ql2bZGdnO7bN4z4Si3kNpv3NR/O9DK/Xw9r1oxkIrAUL79y506rV19dbNfO9IO36Wwud5ho2tsx5LD093RqjBRL369cvavtgvidYVVVljXHz3iKiR3uvWHs/44wzzojF7sSEea4nor/nsWXLFqu2du1ax/aqVausMdrcGbRzQj4JAQAAAAAAAAAAfMFNCAAAAAAAAAAA4AtuQgAAAAAAAAAAAF9wEwIAAAAAAAAAAPgiqsHUGjMkS0Ske/fuVs0MIdSsWbOmwTHbtm2zap9++qlVW7FihVUzA0EILEp8qanOP4GcnBxrjBkI7JYWRKgFxZihYVr4pRYmY4anar3vNkTM/DvVwqK0sFucuLS0NFfjzMBerVe1wNWFCxdaNa/hRNu3b3dsa3Nr586drVpWVpan59P+9vLy8hzbGzZssMZowXXM5w0rLS319H3acb5Vq1ZWraKiwrFt9pOIfpw3g6mbNm3qar+0XjRfoxaCt3HjRqtm9hQhxd5oAau5ublWTQtOjxYtvFoLztTCLRE+Ws+Z534i9jFVC0Z0G5Du1ZdffunY1oKpzXlURA805JiXOLQe1s4dzXMm7fimBbG6YYZhiujh6loAMPxh/o3v3bvXGqMFoPrp66+/tmo//PCDVTPPs7R9147B2rzG+Vg4mOfurVu3tsb07t3bqg0cONDT82mhvnPnznVsa9fNnPvFlhZM3bFjxwa/z+2xrLKy0rE9depUa4x27am9j2e+96ade2nvsZg9pYWfm+8Hat+nfa/bxwraPMm7igAAAAAAAAAAwBfchAAAAAAAAAAAAL7gJgQAAAAAAAAAAPAFNyEAAAAAAAAAAIAvfA+m9koL1HBj+vTpVm3JkiVWbceOHVbNa1grwkELdjPDcLQgwjPOOMPT82khbosXL7ZqZjiXFkKjBb+agU5mYG9jaOFy+DszzEcLAdJCx7XAK3Puadu27YntnE/mzZtn1cwQaC0grqioyKoNHjw4avvVsmVLx7YWgKyFSWlhiUELaQoiLdjSzRgtcM6c/7S/o/z8fKtmztNaiJlbHTp0cGwXFBRYY7QgdfPvm9BXd8wgQi2EumfPnlbt5JNPbvCxt27datW0EM6VK1c6trUAOq/nnAg+r6G+Xbp0aXDMiZg5c6ZV++abbxzby5Yts8ZoYZvaXMrxrfHchpi7oR0jvIbqavuVmZlp1czjrtfzS+262Tz/E9HnW46NsWP2jnb9qAU+R9OmTZsc21pYrHmdK2Jfd9I3ic887hYXF1tjhg4dGrXnmz17tlVbtWqVY1sLFubY6R8378WJ6NeCXr311luO7WnTplljtm3bZtW0+dR8r1h7b8HNXOb1XCCR8EkIAAAAAAAAAADgC25CAAAAAAAAAAAAX3ATAgAAAAAAAAAA+CKwmRDaOlwaMwNCW8dSW6ud/Ifko61D17x5c8d2t27drDFjxozx9Hz19fVW7ZNPPrFq8+fPb/D72rVrZ9XKysoc29ra+G6RCXF85tp92u+ourraqplrkYuIlJeXO7bjkQkxd+5cx7aWVaJlmrjpE2299d27d1u1Hj16NPhYaJi2hqS2vr25fr72exoyZIinfdAyFLQ1/c2ato65lm2jPb4brDEcW2b+g4id4dKnTx9rzDnnnOPp+davX2/Vtm/fbtXMeVhbxzzZ1mJNJtq5X3p6ulUzs7eaNWvm6vH37NnT4JjKykqrNmfOHKu2YsUKx7aW/6Ct8c5c502TJs7/i6cda7yeW2u/E239cTfXo1qGibZmdseOHV3u3fGZ6/yL6FmKZJGEk9ffkXaMN+dSbW41/86Q+Ny856LlLp3Iexkm7drWPKa6fb8R0aFlLOXk5Fg17b0R7TzKDTNbS8uo4bog9jgqAAAAAAAAAAAAX3ATAgAAAAAAAAAA+IKbEAAAAAAAAAAAwBfchAAAAAAAAAAAAL7wPZhaC8isqKiwalrAoBtm4OC2bdusMYRQI9oGDx7s6fs6depk1cxwQi24Tvs+M0TRrUOHDlm1qqoqx7YW5q59X7Iww4m0eU2be3766Ser9u233zq2tTAkN7Tn0+bWJUuWNFhbt26dNcZrgKIW0ql9nxlWTXCdN26Dqc1QyeXLl1tj5s2bZ9Xat29/Ant3fF7nMMSfmxBqEZEBAwY4ti+99FJPz2cGqx/LokWLrJp5PCNsDrE2d+5cq2aGUIvYx3VCqKNHO8fIyMhwbGvBzv3797dqbkPLTVrgs/Y7Npn7KSJSWlpq1bR99UILRDfP2UToxaDRfh/atZs57kTOxUpKShzb3bt3t8Zo1xhmqLl27UB/hZc2R+bl5Tm2e/To4eqxtGtbk/k+hoj9HqGIfW3L+WD8acdmrab9jk3anGEez8y5R4Q+iAfe9QEAAAAAAAAAAL7gJgQAAAAAAAAAAPAFNyEAAAAAAAAAAIAvuAkBAAAAAAAAAAB8EdVgai3UQwtd1YJi3NDClczH1wJQCRtBPOTk5Fi1gQMHuqqZtDCexYsXe9sxhfk3WVNTY41J5mBqkxZ8pAU5a3Od+b0LFizwtA9aeLgWJrh582artn37dse2Nk9rr9GcS1NSUqwxWnih1r/mOK9Bj+ZrEdGDmZOJdswz+1P7nfzwww9WLSsry7E9ZMiQBscExcKFC62aGVy8fv16a4wWkJjM5xFaCHXr1q2tmnYsu/zyyz09pxYcZ/rb3/5m1bQ5kGMXouW7777z9H3aXLRx40arZs49BLNGjzaPZWZmOrbbtGljjSksLLRqXbp0cfX4brg5tmjnWm6ez2v/mAHpIvpxkbk1vszfr3buq/3ezOPriQRTm4YNG2bVtGtK8/0a7Vysvr7eqrm5NkFsafOT1lOlpaWO7ZYtW0ZtH2bMmGHVKisrrVqyXx8muk2bNlk1c/7R3itG7PFJCAAAAAAAAAAA4AtuQgAAAAAAAAAAAF9wEwIAAAAAAAAAAPgiqpkQGm3drV27dnl6LG3tSdYBhFtar5hrA2rr52trCg4ePDhq+xVrU6dOtWrLly93bGv5Bvyt/Z32s9DWMK+urrZq5vyXlpbmaR+0dS21fdDGmfOy13WDtZ+DNk9r/bR3717HtramqBvaMSbZ14zVXuuBAwcc29ra+XPnzrVq5pq8a9eutcb06NHDqnXq1MmqFRQUOLa1XAGth8191fa9vLzcqs2bN8+qff/9947t1atXW2O0fk2mtdnNv8XmzZtbY3r37m3Vhg8f7ts+TZs2zappx2ZzXgHcHq/N8z9tPkxN9XbZtGLFCqu2Y8cOq8ZaxYimdevWuRpnnpdu2LDBGkNWUvCY59vauYt2vmTW8vLyortjBu1c79RTT3Vsa3Orlpuj5USY86Z2HZLs1wV+cpsbZl4DaLS5R2Pmu2m5S1p2Ijk2iU2bA833Qfi7DwY+CQEAAAAAAAAAAHzBTQgAAAAAAAAAAOALbkIAAAAAAAAAAABfcBMCAAAAAAAAAAD4wvdgai38g+A1xIPWi2bA1cqVK60xH374oVWrq6tzbA8bNswaM2DAgMbu4gnRQhQXLFhg1RYvXmzVzPA6LcwYx6eFnmkhqWYgptdAZq2f3db85HYf6LHYMvvTnMNE9NDpmpoax7YWBjxnzhyr1rZt2wZrbkLqNFpY4Zo1a6yaFjq9fv16x7YWDqv1ZjIHmTVpEvv/r/KXv/zFsb1s2TJrzO7du61aMv+eoHMbTL1p0ybHthZs75UWDqsFrNK/OBFugqi1eXPJkiWO7fLycmsM/Ro85nmd9rvVztnMa8Pq6uqo7le05ObmWrXMzEyrZp6zab2qBaubIcX0c3iYPbx161ZrDNeZweP2vZJt27Z5enzCyMODT0IAAAAAAAAAAABfcBMCAAAAAAAAAAD4gpsQAAAAAAAAAADAF9yEAAAAAAAAAAAAvvA9mBoIMjO0yAwmFBGZPXu2VTNDBhctWmSN6dWrl1VLS0tr7C6KiB6wumrVKse2Fj6mhSHu2rXLqpk/By04CI0XhKBoQKMFdWnBfWaAqxb6pQVaZ2VlWbWcnJzjbrtlhmWL6AHTtbW1Vs18jdrPgb/R6NGOQaapU6datcWLFzu2teMWvye4ofXJwYMHrZo5r2jh1V6fUwvI1PaBnvaPNtfX1dU5trVAZu2Ypx27UlODd0ntNgTUPH5qoaDa99Gv8WX+frXj5NKlS61a06ZNHdtNmnj/P6ktW7b0/L1Ibtr7KxptDl6zZo1jW5ufEDzaMUm7VtPeV3Njw4YNVk27tkX88UkIAAAAAAAAAADgC25CAAAAAAAAAAAAX3ATAgAAAAAAAAAA+IKbEAAAAAAAAAAAwBcpEZepUikpKX7vC0IkVmFkse477fnMAC8RkYyMDMe2FsyVl5fn6rHc2L59u1UzA8jq6+utMQcOHLBqYQ5LjsV+MtfhHyXqXOeVtp9aTQs6bNas2XG33dLmNa0W5tDpePadWcvNzbXGdO/e3dPzaQFxlZWVVm337t2O7bD83sIumY+x5n5Fcz/DfN7ltyDNdVq4tHberh3fgtrXJu24aIaFaqHpWqBomCXiXKedU7Vo0cKqtWrVytPja31hXg9nZmZ6euz9+/dbtX379rkaZ9a062Ht3MP8W/C7JxL1ekKbI7Ozs61aYWGhp8fXfp9btmxxbGvB1BxjfxakvtPGNG/e3KoVFxd72gct5Hr9+vWObe16EdHXUN/xSQgAAAAAAAAAAOALbkIAAAAAAAAAAABfcBMCAAAAAAAAAAD4gkwIeBKk9eXiwVwPVluHMz093ap5fT1u1sVMhjWHE3ENVwRbss91XrlZf9vra3Y714V5/gtS32lrPLdu3drT85lZD8eqhfl3F2YcYxFrQZrrgvz4XjCPHlsiznVaVomWc+I1j0vLBTGfMy0tzdV+eX0+7fdmZlVo2RValkSsc04SZa5z83xaj3nNC9HW8DffF9GybvCzoPed1itapogbWq/U1dU5tjkuxgaZEAAAAAAAAAAAIC64CQEAAAAAAAAAAHzBTQgAAAAAAAAAAOALbkIAAAAAAAAAAABfuA6mBgAAAAAAAAAAaAw+CQEAAAAAAAAAAHzBTQgAAAAAAAAAAOALbkIAAAAAAAAAAABfcBMCAAAAAAAAAAD4gpsQAAAAAAAAAADAF9yEAAAAAAAAAAAAvuAmBAAAAAAAAAAA8AU3IQAAAAAAAAAAgC+4CQEAAAAAAAAAAHzx/wGJA8EX98+bbwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict(image):\n",
    "    # Применяем преобразования к изображению, если они требуются\n",
    "    # image = transform(input_image)  # Примените необходимые преобразования\n",
    "    # Убедитесь, что изображение имеет форму (1, 1, H, W) для модели\n",
    "    if image.dim() == 2:  # Если изображение 2D (H, W)\n",
    "        image = image.unsqueeze(0)  # Добавляем размер канала\n",
    "    image = image.unsqueeze(0)  # Добавляем размер батча\n",
    "\n",
    "    #print('image shape:', image.shape)\n",
    "\n",
    "    with torch.no_grad():  # Отключаем градиенты для повышения производительности\n",
    "        output = model_cnn(image)  # Получаем выход модели\n",
    "        _, predicted_class = torch.max(output.data, 1)  # Находим класс с максимальной вероятностью\n",
    "        predicted_label = predicted_class.item()  # Получаем метку класса как целое число\n",
    "        #print('predicted_label:', predicted_label)\n",
    "\n",
    "        pred = label_dict[predicted_label]  # Получаем предсказанную метку\n",
    "        #print('predicted symbol:', pred)\n",
    "\n",
    "    return pred\n",
    "\n",
    "# Проверяем предсказания\n",
    "fig, axs = plt.subplots(1, 10, figsize=(20, 5))\n",
    "for i in range(10):\n",
    "    random_index = np.random.randint(0, len(train_data))\n",
    "    #print('Random index:', random_index)\n",
    "    image, label = train_data[random_index]\n",
    "\n",
    "    # Преобразование изображения в NumPy массив для корректного отображения\n",
    "    image_np = image.squeeze(0).numpy()  # Убираем размер канала и преобразуем в NumPy массив\n",
    "\n",
    "    pred = predict(image)  # Предсказание для изображения\n",
    "\n",
    "    # Отображаем изображение\n",
    "    axs[i].imshow(image_np, cmap='gray')  # Используем cmap='gray' для черно-белых изображений\n",
    "    # Добавляем отображение истинной метки и предсказанного значения\n",
    "    axs[i].set_title(f'True: {label_dict[label]}\\nPred: {pred}')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c4f4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Устанавливаем модель в режим оценки\n",
    "    criterion = nn.CrossEntropyLoss()  # Функция потерь\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    class_correct = [0] * 47  # Для каждого из 47 классов\n",
    "    class_total = [0] * 47\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)  # Получаем предсказания от модели\n",
    "            \n",
    "            # Вычисление потерь\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Получение предсказаний\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "            # Подсчет правильных предсказаний для каждого класса\n",
    "            for i in range(len(target)):\n",
    "                label = target[i].item()  # Получаем метку класса\n",
    "                class_correct[label] += (pred[i] == label).item()  # Увеличиваем счетчик для правильного предсказания\n",
    "                class_total[label] += 1  # Увеличиваем общее количество примеров для данного класса\n",
    "\n",
    "    # Вычисляем общую точность и среднюю потерю\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "\n",
    "    print(f'Overall Accuracy: {accuracy:.4f}')\n",
    "    print(f'Average Loss: {average_loss:.4f}')\n",
    "\n",
    "    # Вывод результатов по каждому классу\n",
    "    for i in range(47):\n",
    "        if class_total[i] > 0:  # Избегаем деления на ноль\n",
    "            class_accuracy = class_correct[i] / class_total[i]\n",
    "            #print(f'Accuracy of class {i}: {class_accuracy:.2f}')\n",
    "        else:\n",
    "            print(f'Class {i} has no samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41684e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8255\n",
      "Average Loss: 0.5957\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_cnn, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8cdcb5",
   "metadata": {},
   "source": [
    "### Первоначальная модель после первого этапа обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c5a44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение трансформаций для нормализации данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Нормализация по среднему и стандартному отклонению\n",
    "])\n",
    "\n",
    "# Загрузка обучающего набора данных с трансформациями\n",
    "train_data = EMNIST('data_c/', 'balanced', train=True, download=True,\n",
    "                transform=torchvision.transforms.Compose([ # Поворот и отражение\n",
    "                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))\n",
    "\n",
    "\n",
    "# Загрузка тестового набора данных с трансформациями\n",
    "test_data = EMNIST('data_c/', 'balanced', train=False,\n",
    "                transform=torchvision.transforms.Compose([ # Поворот и отражение\n",
    "                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f1ca9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoches 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5215/1202297313.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('data/model_a_checkpoint.ckpt')\n",
      "/tmp/ipykernel_5215/1202297313.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_cnn.load_state_dict(torch.load('data/model_a.ckpt'))  # Замените на путь к вашей модели\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка модели\n",
    "model_cnn = CNNModel() \n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.001) \n",
    "\n",
    "# Загрузка контрольной точки\n",
    "checkpoint = torch.load('data/model_a_checkpoint.ckpt')\n",
    "\n",
    "# Восстановление состояния модели и оптимизатора\n",
    "model_cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Если нужно, можно восстановить номер эпохи\n",
    "n_epoch = checkpoint['epoch']\n",
    "print('epoches', n_epoch)\n",
    "\n",
    "# Восстановление номера эпохи\n",
    "start_epoch = checkpoint['epoch'] + 1  # Начинаем с следующей эпохи\n",
    "\n",
    "# Параметры для продолжения обучения\n",
    "n_epochs_to_continue = 5  # Количество дополнительных эпох\n",
    "\n",
    "# Загрузка предварительно обученной модели\n",
    "model_cnn = CNNModel()  # Предполагается, что модель определена\n",
    "model_cnn.load_state_dict(torch.load('data/model_a.ckpt'))  # Замените на путь к вашей модели\n",
    "#model.eval()  # Установка модели в режим оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3589e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes with accuracy < 0.87:\n",
      "0\n",
      "Accuracy of class 0: 0.67\n",
      "1\n",
      "Accuracy of class 1: 0.81\n",
      "9\n",
      "Accuracy of class 9: 0.81\n",
      "F\n",
      "Accuracy of class 15: 0.67\n",
      "I\n",
      "Accuracy of class 18: 0.61\n",
      "L\n",
      "Accuracy of class 21: 0.41\n",
      "O\n",
      "Accuracy of class 24: 0.67\n",
      "Y\n",
      "Accuracy of class 34: 0.86\n",
      "f\n",
      "Accuracy of class 40: 0.63\n",
      "g\n",
      "Accuracy of class 41: 0.68\n",
      "q\n",
      "Accuracy of class 44: 0.50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Инициализация переменных для хранения результатов\n",
    "class_correct = [0] * 47  # Для каждого из 47 классов\n",
    "class_total = [0] * 47\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "with torch.no_grad():\n",
    "    for data, target in val_loader:\n",
    "        output = model_cnn(data)  # Получение предсказаний от модели\n",
    "        _, predicted = torch.max(output, 1)  # Получение индексов классов с максимальным значением вероятности\n",
    "\n",
    "        # Подсчет правильных предсказаний для каждого класса\n",
    "        for i in range(len(target)):\n",
    "            label = target[i].item()  # Получение метки класса\n",
    "            class_correct[label] += (predicted[i] == label).item()  # Увеличение счетчика для правильного предсказания\n",
    "            class_total[label] += 1  # Увеличение общего количества примеров для данного класса\n",
    "\n",
    "\n",
    "# Вывод результатов по каждому классу с accuracy < 0.87\n",
    "print(\"Classes with accuracy < 0.87:\")\n",
    "for i in range(47):\n",
    "    if class_total[i] > 0:  # Избегаем деления на ноль\n",
    "        accuracy = class_correct[i] / class_total[i]\n",
    "        if accuracy < 0.87:  # Проверяем условие на точность\n",
    "            print(label_dict[i])  # Выводим метку класса\n",
    "            print(f'Accuracy of class {i}: {accuracy:.2f}')\n",
    "    else:\n",
    "        print(f'Class {i} has no samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df42922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8773\n",
      "Average Loss: 0.3945\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_cnn, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a44502",
   "metadata": {},
   "source": [
    "# Выводы о проделаной работе:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c100474",
   "metadata": {},
   "source": [
    "### Негативные последствия излишней сложности модели, лишнего количества эпох обучения и лишних этапов дообучения\n",
    "\n",
    "В машинном обучении, особенно в контексте глубокого обучения с использованием PyTorch, важно правильно настраивать архитектуру модели и параметры обучения. Излишняя сложность модели, слишком большое количество эпох и лишние этапы дообучения могут привести к ряду негативных последствий.\n",
    "\n",
    "#### 1. Излишняя сложность модели на простых данных\n",
    "\n",
    "**Проблема**: Если модель слишком сложная (например, содержит слишком много слоев или параметров) для простых данных, это может привести к переобучению.\n",
    "\n",
    "**Негативные последствия**:\n",
    "- **Переобучение**: Модель начинает \"запоминать\" обучающие данные вместо того, чтобы обобщать на новые данные. Это означает, что она будет показывать высокую точность на обучающем наборе, но низкую точность на валидационном или тестовом наборе.\n",
    "- **Увеличение времени обучения**: Сложные модели требуют больше времени на обучение из-за большого количества параметров.\n",
    "- **Сложность интерпретации**: Более сложные модели труднее интерпретировать и отлаживать, что может затруднить выявление проблем.\n",
    "\n",
    "#### 2. Лишнее количество эпох обучения\n",
    "\n",
    "**Проблема**: Если модель обучается слишком долго (больше необходимого количества эпох), это также может привести к переобучению.\n",
    "\n",
    "**Негативные последствия**:\n",
    "- **Переобучение**: Как и в случае с излишней сложностью модели, избыточное обучение приводит к тому, что модель начинает подстраиваться под шум в данных, что ухудшает её способность обобщать.\n",
    "- **Неэффективное использование ресурсов**: Длительное обучение требует больше вычислительных ресурсов и времени, что может быть нецелесообразно.\n",
    "- **Сложности с мониторингом метрик**: При длительном обучении может быть сложно отслеживать метрики валидации и вовремя остановить обучение.\n",
    "\n",
    "#### 3. Лишние этапы дообучения модели\n",
    "\n",
    "**Проблема**: Использование слишком большого количества этапов дообучения может привести к тому же эффекту переобучения.\n",
    "\n",
    "**Негативные последствия**:\n",
    "- **Неоптимальные результаты**: Каждый дополнительный этап дообучения увеличивает риск того, что модель начнет терять обобщающую способность.\n",
    "- **Сложности с настройкой гиперпараметров**: При каждом новом этапе дообучения могут потребоваться новые настройки гиперпараметров (например, скорость обучения), что усложняет процесс обучения.\n",
    "- **Увеличение времени до достижения результата**: Лишние этапы могут замедлить процесс получения окончательных результатов.\n",
    "\n",
    "### Рекомендации по предотвращению негативных последствий\n",
    "\n",
    "1. **Используйте простые модели для простых задач**: Начинайте с простой архитектуры и постепенно увеличивайте её сложность только при необходимости.\n",
    "2. **Мониторинг метрик валидации**: Используйте методы ранней остановки (early stopping), чтобы прекратить обучение, когда валидационная точность перестает улучшаться.\n",
    "3. **Регуляризация**: Применяйте методы регуляризации, такие как дропаут или L2-регуляризация, чтобы предотвратить переобучение.\n",
    "4. **Аугментация данных**: Увеличьте объем данных с помощью аугментации, чтобы модель могла лучше обобщать.\n",
    "5. **Оптимизация гиперпараметров**: Используйте автоматизированные методы подбора гиперпараметров для нахождения оптимальных значений.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d3397",
   "metadata": {},
   "source": [
    "## Итог"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d17fe",
   "metadata": {},
   "source": [
    "В качестве базовой модели для сериса выберем модель после первого этапа обучения с десятью эпохаим c lr==0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af9e9951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8773\n",
      "Average Loss: 0.3945\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_cnn, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f3b550",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "Правильная настройка архитектуры модели и параметров обучения критически важна для достижения хороших результатов в задачах машинного обучения. Избегайте излишней сложности модели, лишнего количества эпох и ненужных этапов дообучения для повышения производительности вашей модели на новых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640fafe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
