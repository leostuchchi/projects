{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f919cb9f",
   "metadata": {
    "id": "f919cb9f"
   },
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d826ec1",
   "metadata": {
    "id": "2d826ec1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import EMNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "import cv2\n",
    "import optuna\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ac4f0",
   "metadata": {
    "id": "c84ac4f0"
   },
   "source": [
    "# Получение, трансформация, нормализация и контроль данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af69153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Для обработки изображений х EMNIST с использованием методов Eroding, Dilating и Smoothing Images, \n",
    " создадим функцию, для предобработки перед передачей изображений в модель'''\n",
    "\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Преобразуем изображение PIL в массив NumPy\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Применяем сглаживание (Gaussian Blur)\n",
    "    img_blurred = cv2.GaussianBlur(img_np, (5, 5), 0)\n",
    "\n",
    "    # Применяем эрозию\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_eroded = cv2.erode(img_blurred, kernel, iterations=1)\n",
    "\n",
    "    # Применяем дилатацию\n",
    "    img_dilated = cv2.dilate(img_eroded, kernel, iterations=1)\n",
    "\n",
    "    # Преобразуем обратно в PIL\n",
    "    img_processed = Image.fromarray(img_dilated)\n",
    "\n",
    "    return img_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d6caec",
   "metadata": {
    "id": "c9d6caec"
   },
   "outputs": [],
   "source": [
    "# Определение трансформаций для нормализации данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Нормализация по среднему и стандартному отклонению\n",
    "])\n",
    "\n",
    "# использованием методов Eroding, Dilating и Smoothing Images\n",
    "# Загрузка обучающего набора данных с трансформациями\n",
    "train_data = EMNIST('data_e_c/', 'balanced', train=True, download=True,\n",
    "                transform=torchvision.transforms.Compose([ \n",
    "                    # Применяем обработку изображения\n",
    "                    preprocess_image,\n",
    "                    # Поворот и отражение\n",
    "                    #lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    #lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))\n",
    "\n",
    "# использованием методов Eroding, Dilating и Smoothing Images\n",
    "# Загрузка тестового набора данных с трансформациями\n",
    "test_data = EMNIST('data_e_c/', 'balanced', train=False,\n",
    "                transform=torchvision.transforms.Compose([ \n",
    "                    # Применяем обработку изображения\n",
    "                    preprocess_image,\n",
    "                    # Поворот и отражение\n",
    "                    #lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "                    #lambda img: torchvision.transforms.functional.hflip(img),\n",
    "                    transform # трансформируем и нормализуем\n",
    "                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1864e3f0",
   "metadata": {
    "id": "1864e3f0"
   },
   "outputs": [],
   "source": [
    "# получение маппинга\n",
    "with open('emnist-balanced-mapping.txt', 'r') as f:\n",
    "    mapping = f.readlines()\n",
    "\n",
    "#mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "092862d6",
   "metadata": {
    "id": "092862d6"
   },
   "outputs": [],
   "source": [
    "# Создаем словарь соответствий\n",
    "label_dict = {}\n",
    "for entry in mapping:\n",
    "    label, ascii_code = map(int, entry.split())\n",
    "    label_dict[label] = chr(ascii_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18534804",
   "metadata": {
    "id": "18534804",
    "outputId": "0cad163f-2218-4152-ca6b-4c3e0cf0af6f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Проверяем корректность изображений\n",
    "fig, axs = plt.subplots(1, 10, figsize=(20, 5))\n",
    "for i in range(10):\n",
    "    random_index = np.random.randint(0, len(train_data))\n",
    "    #print('Random index:', random_index)\n",
    "    image, label = train_data[random_index]\n",
    "\n",
    "    # Преобразование изображения в NumPy массив для корректного отображения\n",
    "    image_np = image.numpy()  # Прямое преобразование в NumPy массив\n",
    "\n",
    "    # Убираем размерность канала (если она есть)\n",
    "    if image_np.shape[0] == 1:  # Если канал один (черно-белое изображение)\n",
    "        image_np = image_np.squeeze(0)  # Убираем размерность канала\n",
    "\n",
    "    # Отображаем изображение\n",
    "    axs[i].imshow(image_np, cmap='gray')\n",
    "    axs[i].set_title(label_dict[label])  # Используем словарь для отображения метки\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "499cb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание загрузчиков данных\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83c52ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# простая модель\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # Свертка с 32 фильтрами\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # Свертка с 64 фильтрами\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Подвыборка\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Полносвязный слой\n",
    "        self.fc2 = nn.Linear(128, 47)  # Выходной слой для 47 классов\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Применение свертки и активации ReLU\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Применение свертки и активации ReLU\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Преобразование в вектор для полносвязного слоя\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        x = self.fc2(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb5b5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очищаем состояние для последующей модели\n",
    "def clear_training_state(model, optimizer):\n",
    "    # Удаляем все параметры и градиенты\n",
    "    model.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
    "    optimizer.state.clear()  # Очищаем состояние оптимизатора\n",
    "    optimizer.param_groups.clear()  # Очищаем группы параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ef1acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем функцию для очистки состояния\n",
    "#clear_training_state(model, optimizer)\n",
    "\n",
    "# Инициализация модели\n",
    "model_cnn = CNNModel()\n",
    "\n",
    "# Оптимизатор и функция потерь\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.001)  # Используем Adam с малой скоростью обучения\n",
    "loss_function = nn.CrossEntropyLoss()  # Функция потерь для многоклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc643a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7401\n",
      "Validation Accuracy: 0.8388\n",
      "Epoch 2/10, Loss: 0.4358\n",
      "Validation Accuracy: 0.8529\n",
      "Epoch 3/10, Loss: 0.3788\n",
      "Validation Accuracy: 0.8593\n",
      "Epoch 4/10, Loss: 0.3439\n",
      "Validation Accuracy: 0.8596\n",
      "Epoch 5/10, Loss: 0.3153\n",
      "Validation Accuracy: 0.8698\n",
      "Epoch 6/10, Loss: 0.2919\n",
      "Validation Accuracy: 0.8651\n",
      "Epoch 7/10, Loss: 0.2720\n",
      "Validation Accuracy: 0.8698\n",
      "Epoch 8/10, Loss: 0.2530\n",
      "Validation Accuracy: 0.8643\n",
      "Epoch 9/10, Loss: 0.2389\n",
      "Validation Accuracy: 0.8689\n",
      "Epoch 10/10, Loss: 0.2248\n",
      "Validation Accuracy: 0.8702\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model_cnn.train()  # Устанавливаем режим обучения\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()  # Обнуляем градиенты\n",
    "        output = model_cnn(data)  # Прямой проход через модель\n",
    "        loss = loss_function(output, target)  # Вычисление потерь\n",
    "        loss.backward()  # Обратный проход (вычисление градиентов)\n",
    "        optimizer.step()  # Обновление параметров\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Валидация модели после каждой эпохи\n",
    "    model_cnn.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model_cnn(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1651aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели в формате .ckpt\n",
    "torch.save(model_cnn.state_dict(), 'model_ec_1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be786795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#упрощенная модель\n",
    "\n",
    "class SimplifiedCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimplifiedCNNModel, self).__init__()\n",
    "        # Первый свертка + активация + подвыборка\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # Уменьшено до 16 фильтров\n",
    "        self.bn1 = nn.BatchNorm2d(16)  # Нормализация\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Подвыборка\n",
    "        \n",
    "        # Второй свертка + активация + подвыборка\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)  # Уменьшено до 32 фильтров\n",
    "        self.bn2 = nn.BatchNorm2d(32)  # Нормализация\n",
    "        \n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)  # Измените размер в зависимости от входного размера\n",
    "        self.fc2 = nn.Linear(128, 47)  # Выходной слой для 47 классов\n",
    "        self.dropout = nn.Dropout(0.5)  # Дропаут для регуляризации\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # Свертка 1\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # Свертка 2\n",
    "        x = x.view(-1, 32 * 7 * 7)  # Преобразование в вектор для полносвязного слоя\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Применение дропаута\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef9d01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем функцию для очистки состояния\n",
    "clear_training_state(model_cnn, optimizer)\n",
    "\n",
    "# Инициализация модели\n",
    "model_cnn_2 = SimplifiedCNNModel()\n",
    "\n",
    "# Оптимизатор и функция потерь\n",
    "optimizer = optim.Adam(model_cnn_2.parameters(), lr=0.001)  # Используем Adam с малой скоростью обучения\n",
    "loss_function = nn.CrossEntropyLoss()  # Функция потерь для многоклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c32a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание загрузчиков данных\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a10beb51",
   "metadata": {
    "id": "a10beb51",
    "outputId": "c9f3e4c5-df0d-4efd-b2ee-383bc62bd939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3496\n",
      "Validation Accuracy: 0.8053\n",
      "Epoch 2/10, Loss: 0.9355\n",
      "Validation Accuracy: 0.8201\n",
      "Epoch 3/10, Loss: 0.8472\n",
      "Validation Accuracy: 0.8371\n",
      "Epoch 4/10, Loss: 0.7925\n",
      "Validation Accuracy: 0.8376\n",
      "Epoch 5/10, Loss: 0.7529\n",
      "Validation Accuracy: 0.8407\n",
      "Epoch 6/10, Loss: 0.7190\n",
      "Validation Accuracy: 0.8452\n",
      "Epoch 7/10, Loss: 0.6943\n",
      "Validation Accuracy: 0.8494\n",
      "Epoch 8/10, Loss: 0.6731\n",
      "Validation Accuracy: 0.8537\n",
      "Epoch 9/10, Loss: 0.6593\n",
      "Validation Accuracy: 0.8564\n",
      "Epoch 10/10, Loss: 0.6443\n",
      "Validation Accuracy: 0.8603\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model_cnn_2.train()  # Устанавливаем режим обучения\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()  # Обнуляем градиенты\n",
    "        output = model_cnn_2(data)  # Прямой проход через модель\n",
    "        loss = loss_function(output, target)  # Вычисление потерь\n",
    "        loss.backward()  # Обратный проход (вычисление градиентов)\n",
    "        optimizer.step()  # Обновление параметров\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Валидация модели после каждой эпохи\n",
    "    model_cnn_2.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model_cnn_2(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfaab1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели в формате .ckpt\n",
    "torch.save(model_cnn_2.state_dict(), 'model_ec_2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e227e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BigCNNModel, self).__init__()\n",
    "        # Первый свертка + активация + подвыборка\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 32 фильтра\n",
    "        self.bn1 = nn.BatchNorm2d(32)  # Нормализация\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Подвыборка\n",
    "        # Второй свертка + активация + подвыборка\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 64 фильтра\n",
    "        self.bn2 = nn.BatchNorm2d(64)  # Нормализация\n",
    "        # Третий свертка\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 128 фильтров\n",
    "        self.bn3 = nn.BatchNorm2d(128)  # Нормализация\n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)  # Измените размер в зависимости от входного размера\n",
    "        self.fc2 = nn.Linear(256, 47)  # Выходной слой для 47 классов\n",
    "        self.dropout = nn.Dropout(0.5)  # Дропаут для регуляризации\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # Свертка 1\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # Свертка 2\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # Свертка 3\n",
    "        x = x.view(-1, 128 * 3 * 3)  # Преобразование в вектор для полносвязного слоя\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Применение дропаута\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac426ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем функцию для очистки состояния\n",
    "clear_training_state(model_cnn_2, optimizer)\n",
    "\n",
    "# Инициализация модели\n",
    "model_cnn_3 = BigCNNModel()\n",
    "\n",
    "# Оптимизатор и функция потерь\n",
    "optimizer = optim.Adam(model_cnn_3.parameters(), lr=0.001)  # Используем Adam с малой скоростью обучения\n",
    "loss_function = nn.CrossEntropyLoss()  # Функция потерь для многоклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "744b7daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание загрузчиков данных\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04eeb1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8329\n",
      "Validation Accuracy: 0.8534\n",
      "Epoch 2/10, Loss: 0.5108\n",
      "Validation Accuracy: 0.8701\n",
      "Epoch 3/10, Loss: 0.4493\n",
      "Validation Accuracy: 0.8684\n",
      "Epoch 4/10, Loss: 0.4152\n",
      "Validation Accuracy: 0.8769\n",
      "Epoch 5/10, Loss: 0.3882\n",
      "Validation Accuracy: 0.8733\n",
      "Epoch 6/10, Loss: 0.3665\n",
      "Validation Accuracy: 0.8807\n",
      "Epoch 7/10, Loss: 0.3498\n",
      "Validation Accuracy: 0.8846\n",
      "Epoch 8/10, Loss: 0.3352\n",
      "Validation Accuracy: 0.8845\n",
      "Epoch 9/10, Loss: 0.3247\n",
      "Validation Accuracy: 0.8863\n",
      "Epoch 10/10, Loss: 0.3092\n",
      "Validation Accuracy: 0.8863\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model_cnn_3.train()  # Устанавливаем режим обучения\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()  # Обнуляем градиенты\n",
    "        output = model_cnn_3(data)  # Прямой проход через модель\n",
    "        loss = loss_function(output, target)  # Вычисление потерь\n",
    "        loss.backward()  # Обратный проход (вычисление градиентов)\n",
    "        optimizer.step()  # Обновление параметров\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Валидация модели после каждой эпохи\n",
    "    model_cnn_3.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model_cnn_3(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e46bf105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели в формате .ckpt\n",
    "torch.save(model_cnn_3.state_dict(), 'model_ec_3.ckpt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "563e135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6123/2947927078.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model_ec_3.ckpt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BigCNNModel                              [1, 47]                   --\n",
       "├─Conv2d: 1-1                            [1, 32, 28, 28]           320\n",
       "├─BatchNorm2d: 1-2                       [1, 32, 28, 28]           64\n",
       "├─MaxPool2d: 1-3                         [1, 32, 14, 14]           --\n",
       "├─Conv2d: 1-4                            [1, 64, 14, 14]           18,496\n",
       "├─BatchNorm2d: 1-5                       [1, 64, 14, 14]           128\n",
       "├─MaxPool2d: 1-6                         [1, 64, 7, 7]             --\n",
       "├─Conv2d: 1-7                            [1, 128, 7, 7]            73,856\n",
       "├─BatchNorm2d: 1-8                       [1, 128, 7, 7]            256\n",
       "├─MaxPool2d: 1-9                         [1, 128, 3, 3]            --\n",
       "├─Linear: 1-10                           [1, 256]                  295,168\n",
       "├─Dropout: 1-11                          [1, 256]                  --\n",
       "├─Linear: 1-12                           [1, 47]                   12,079\n",
       "==========================================================================================\n",
       "Total params: 400,367\n",
       "Trainable params: 400,367\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 7.80\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.70\n",
       "Params size (MB): 1.60\n",
       "Estimated Total Size (MB): 2.31\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка предварительно обученной модели\n",
    "model = BigCNNModel()  # модель уже определена\n",
    "model.load_state_dict(torch.load('model_ec_3.ckpt'))\n",
    "\n",
    "# Вывод информации о модели\n",
    "summary(model, input_size=(1, 1, 28, 28))  # Указываем размер входного тензора [batch_size, channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aa60040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W1231 21:10:27.875385805 NNPACK.cpp:61] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict(image):\n",
    "    # Применяем преобразования к изображению, если они требуются\n",
    "    # image = transform(input_image)  # Примените необходимые преобразования\n",
    "    # Убедитесь, что изображение имеет форму (1, 1, H, W) для модели\n",
    "    if image.dim() == 2:  # Если изображение 2D (H, W)\n",
    "        image = image.unsqueeze(0)  # Добавляем размер канала\n",
    "    image = image.unsqueeze(0)  # Добавляем размер батча\n",
    "\n",
    "    #print('image shape:', image.shape)\n",
    "\n",
    "    with torch.no_grad():  # Отключаем градиенты для повышения производительности\n",
    "        output = model_cnn_3(image)  # Получаем выход модели\n",
    "        _, predicted_class = torch.max(output.data, 1)  # Находим класс с максимальной вероятностью\n",
    "        predicted_label = predicted_class.item()  # Получаем метку класса как целое число\n",
    "        #print('predicted_label:', predicted_label)\n",
    "\n",
    "        pred = label_dict[predicted_label]  # Получаем предсказанную метку\n",
    "        #print('predicted symbol:', pred)\n",
    "\n",
    "    return pred\n",
    "\n",
    "# Проверяем предсказания\n",
    "fig, axs = plt.subplots(1, 10, figsize=(20, 5))\n",
    "for i in range(10):\n",
    "    random_index = np.random.randint(0, len(train_data))\n",
    "    #print('Random index:', random_index)\n",
    "    image, label = train_data[random_index]\n",
    "\n",
    "    # Преобразование изображения в NumPy массив для корректного отображения\n",
    "    image_np = image.squeeze(0).numpy()  # Убираем размер канала и преобразуем в NumPy массив\n",
    "\n",
    "    pred = predict(image)  # Предсказание для изображения\n",
    "\n",
    "    # Отображаем изображение\n",
    "    axs[i].imshow(image_np, cmap='gray')  # Используем cmap='gray' для черно-белых изображений\n",
    "    # Добавляем отображение истинной метки и предсказанного значения\n",
    "    axs[i].set_title(f'True: {label_dict[label]}\\nPred: {pred}')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e3816",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b731c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем функцию для очистки состояния\n",
    "#clear_training_state(model_cnn_3, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26153c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение модели\n",
    "class ImprovedCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedCNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Убедитесь в правильном размере\n",
    "        self.fc2 = nn.Linear(128, 47)  # Для 47 классов\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f09476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6434\n",
      "Validation Accuracy: 0.8296\n",
      "Epoch 2/10, Loss: 0.4158\n",
      "Validation Accuracy: 0.8548\n",
      "Epoch 3/10, Loss: 0.3648\n",
      "Validation Accuracy: 0.8637\n",
      "Epoch 4/10, Loss: 0.3321\n",
      "Validation Accuracy: 0.8585\n",
      "Epoch 5/10, Loss: 0.3076\n",
      "Validation Accuracy: 0.8696\n",
      "Epoch 6/10, Loss: 0.2852\n",
      "Validation Accuracy: 0.8736\n",
      "Epoch 7/10, Loss: 0.2676\n",
      "Validation Accuracy: 0.8702\n",
      "Epoch 8/10, Loss: 0.2527\n",
      "Validation Accuracy: 0.8700\n",
      "Epoch 9/10, Loss: 0.2375\n",
      "Validation Accuracy: 0.8735\n",
      "Epoch 10/10, Loss: 0.2241\n",
      "Validation Accuracy: 0.8704\n"
     ]
    }
   ],
   "source": [
    "# Инициализация модели и оптимизатора\n",
    "model = ImprovedCNNModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Обучение модели\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Валидация модели после каждой эпохи\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cba91d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Accuracy of class 0: 0.57\n",
      "1\n",
      "Accuracy of class 1: 0.65\n",
      "2\n",
      "Accuracy of class 2: 0.85\n",
      "3\n",
      "Accuracy of class 3: 0.95\n",
      "4\n",
      "Accuracy of class 4: 0.94\n",
      "5\n",
      "Accuracy of class 5: 0.92\n",
      "6\n",
      "Accuracy of class 6: 0.93\n",
      "7\n",
      "Accuracy of class 7: 0.96\n",
      "8\n",
      "Accuracy of class 8: 0.95\n",
      "9\n",
      "Accuracy of class 9: 0.65\n",
      "A\n",
      "Accuracy of class 10: 0.96\n",
      "B\n",
      "Accuracy of class 11: 0.96\n",
      "C\n",
      "Accuracy of class 12: 0.94\n",
      "D\n",
      "Accuracy of class 13: 0.91\n",
      "E\n",
      "Accuracy of class 14: 0.99\n",
      "F\n",
      "Accuracy of class 15: 0.48\n",
      "G\n",
      "Accuracy of class 16: 0.96\n",
      "H\n",
      "Accuracy of class 17: 0.96\n",
      "I\n",
      "Accuracy of class 18: 0.61\n",
      "J\n",
      "Accuracy of class 19: 0.93\n",
      "K\n",
      "Accuracy of class 20: 0.98\n",
      "L\n",
      "Accuracy of class 21: 0.56\n",
      "M\n",
      "Accuracy of class 22: 0.98\n",
      "N\n",
      "Accuracy of class 23: 0.97\n",
      "O\n",
      "Accuracy of class 24: 0.74\n",
      "P\n",
      "Accuracy of class 25: 0.94\n",
      "Q\n",
      "Accuracy of class 26: 0.94\n",
      "R\n",
      "Accuracy of class 27: 0.96\n",
      "S\n",
      "Accuracy of class 28: 0.90\n",
      "T\n",
      "Accuracy of class 29: 0.94\n",
      "U\n",
      "Accuracy of class 30: 0.93\n",
      "V\n",
      "Accuracy of class 31: 0.91\n",
      "W\n",
      "Accuracy of class 32: 0.98\n",
      "X\n",
      "Accuracy of class 33: 0.96\n",
      "Y\n",
      "Accuracy of class 34: 0.82\n",
      "Z\n",
      "Accuracy of class 35: 0.93\n",
      "a\n",
      "Accuracy of class 36: 0.90\n",
      "b\n",
      "Accuracy of class 37: 0.92\n",
      "d\n",
      "Accuracy of class 38: 0.95\n",
      "e\n",
      "Accuracy of class 39: 0.97\n",
      "f\n",
      "Accuracy of class 40: 0.73\n",
      "g\n",
      "Accuracy of class 41: 0.63\n",
      "h\n",
      "Accuracy of class 42: 0.93\n",
      "n\n",
      "Accuracy of class 43: 0.91\n",
      "q\n",
      "Accuracy of class 44: 0.65\n",
      "r\n",
      "Accuracy of class 45: 0.92\n",
      "t\n",
      "Accuracy of class 46: 0.90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Инициализация переменных для хранения результатов\n",
    "class_correct = [0] * 47  # Для каждого из 47 классов\n",
    "class_total = [0] * 47\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "with torch.no_grad():\n",
    "    for data, target in val_loader:\n",
    "        output = model(data)  # Получение предсказаний от модели\n",
    "        _, predicted = torch.max(output, 1)  # Получение индексов классов с максимальным значением вероятности\n",
    "\n",
    "        # Подсчет правильных предсказаний для каждого класса\n",
    "        for i in range(len(target)):\n",
    "            label = target[i].item()  # Получение метки класса\n",
    "            class_correct[label] += (predicted[i] == label).item()  # Увеличение счетчика для правильного предсказания\n",
    "            class_total[label] += 1  # Увеличение общего количества примеров для данного класса\n",
    "\n",
    "# Вывод результатов по каждому классу\n",
    "for i in range(47):\n",
    "    if class_total[i] > 0:  # Избегаем деления на ноль\n",
    "        accuracy = class_correct[i] / class_total[i]\n",
    "        print(label_dict[i])\n",
    "        print(f'Accuracy of class {i}: {accuracy:.2f}')\n",
    "    else:\n",
    "        print(f'Class {i} has no samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e78f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели в формате .ckpt\n",
    "torch.save(model.state_dict(), 'model_err_f.ckpt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b4f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes with accuracy < 0.87:\n",
      "0\n",
      "Accuracy of class 0: 0.57\n",
      "1\n",
      "Accuracy of class 1: 0.65\n",
      "2\n",
      "Accuracy of class 2: 0.85\n",
      "9\n",
      "Accuracy of class 9: 0.65\n",
      "F\n",
      "Accuracy of class 15: 0.48\n",
      "I\n",
      "Accuracy of class 18: 0.61\n",
      "L\n",
      "Accuracy of class 21: 0.56\n",
      "O\n",
      "Accuracy of class 24: 0.74\n",
      "Y\n",
      "Accuracy of class 34: 0.82\n",
      "f\n",
      "Accuracy of class 40: 0.73\n",
      "g\n",
      "Accuracy of class 41: 0.63\n",
      "q\n",
      "Accuracy of class 44: 0.65\n"
     ]
    }
   ],
   "source": [
    "# Вывод результатов по каждому классу с accuracy < 0.87\n",
    "print(\"Classes with accuracy < 0.87:\")\n",
    "for i in range(47):\n",
    "    if class_total[i] > 0:  # Избегаем деления на ноль\n",
    "        accuracy = class_correct[i] / class_total[i]\n",
    "        if accuracy < 0.87:  # Проверяем условие на точность\n",
    "            print(label_dict[i])  # Выводим метку класса\n",
    "            print(f'Accuracy of class {i}: {accuracy:.2f}')\n",
    "    else:\n",
    "        print(f'Class {i} has no samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7178d31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6123/253852981.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model_err_f.ckpt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка предварительно обученной модели\n",
    "model = ImprovedCNNModel()  # модель уже определена\n",
    "model.load_state_dict(torch.load('model_err_f.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a028368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W104 14:30:13.192678263 NNPACK.cpp:61] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ImprovedCNNModel                         [1, 47]                   --\n",
       "├─Conv2d: 1-1                            [1, 32, 28, 28]           320\n",
       "├─BatchNorm2d: 1-2                       [1, 32, 28, 28]           64\n",
       "├─MaxPool2d: 1-3                         [1, 32, 14, 14]           --\n",
       "├─Conv2d: 1-4                            [1, 64, 14, 14]           18,496\n",
       "├─BatchNorm2d: 1-5                       [1, 64, 14, 14]           128\n",
       "├─MaxPool2d: 1-6                         [1, 64, 7, 7]             --\n",
       "├─Linear: 1-7                            [1, 128]                  401,536\n",
       "├─Linear: 1-8                            [1, 47]                   6,063\n",
       "==========================================================================================\n",
       "Total params: 426,607\n",
       "Trainable params: 426,607\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 4.28\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.60\n",
       "Params size (MB): 1.71\n",
       "Estimated Total Size (MB): 2.31\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывод информации о модели\n",
    "summary(model, input_size=(1, 1, 28, 28))  # Указываем размер входного тензора [batch_size, channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981243d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "190380bd",
   "metadata": {},
   "source": [
    "# Optuna\n",
    "\n",
    "def objective in rotation notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0159a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.30540906788124\n",
    "lr = 0.002184369512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "632567df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем функцию для очистки состояния\n",
    "clear_training_state(model, optimizer)\n",
    "\n",
    "# Создание загрузчиков данных\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ff3dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение модели\n",
    "class TunedCNNModel(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(TunedCNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Убедитесь в правильном размере\n",
    "        self.fc2 = nn.Linear(128, 47)  # Для 47 классов\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d0bba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация модели и оптимизатора\n",
    "model = TunedCNNModel()#.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a23d47",
   "metadata": {},
   "source": [
    "# Enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97f40af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedCNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.dropout = nn.Dropout(0.5)  # Дропаут для регуляризации\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  \n",
    "        self.fc2 = nn.Linear(128, 47)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Применение дропаута перед выходным слоем\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffa409e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем функцию для очистки состояния\n",
    "clear_training_state(model, optimizer)\n",
    "\n",
    "# Создание загрузчиков данных\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1c4529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    n_epochs = 10\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "        # Валидация модели после каждой эпохи\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                output = model(data)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += pred.eq(target).sum().item()\n",
    "\n",
    "        accuracy = correct / len(val_loader.dataset)\n",
    "        print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41f452f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.4310\n",
      "Validation Accuracy: 0.8079\n",
      "Epoch 2/10, Loss: 0.9980\n",
      "Validation Accuracy: 0.8304\n",
      "Epoch 3/10, Loss: 0.8957\n",
      "Validation Accuracy: 0.8402\n",
      "Epoch 4/10, Loss: 0.8367\n",
      "Validation Accuracy: 0.8462\n",
      "Epoch 5/10, Loss: 0.7938\n",
      "Validation Accuracy: 0.8434\n",
      "Epoch 6/10, Loss: 0.7552\n",
      "Validation Accuracy: 0.8538\n",
      "Epoch 7/10, Loss: 0.7190\n",
      "Validation Accuracy: 0.8567\n",
      "Epoch 8/10, Loss: 0.6921\n",
      "Validation Accuracy: 0.8627\n",
      "Epoch 9/10, Loss: 0.6649\n",
      "Validation Accuracy: 0.8631\n",
      "Epoch 10/10, Loss: 0.6304\n",
      "Validation Accuracy: 0.8681\n"
     ]
    }
   ],
   "source": [
    "# Инициализация и обучение модели\n",
    "model = EnhancedCNNModel()\n",
    "train_model(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7b45b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Accuracy of class 0: 0.74\n",
      "1\n",
      "Accuracy of class 1: 0.60\n",
      "2\n",
      "Accuracy of class 2: 0.88\n",
      "3\n",
      "Accuracy of class 3: 0.97\n",
      "4\n",
      "Accuracy of class 4: 0.90\n",
      "5\n",
      "Accuracy of class 5: 0.90\n",
      "6\n",
      "Accuracy of class 6: 0.94\n",
      "7\n",
      "Accuracy of class 7: 0.98\n",
      "8\n",
      "Accuracy of class 8: 0.95\n",
      "9\n",
      "Accuracy of class 9: 0.88\n",
      "A\n",
      "Accuracy of class 10: 0.97\n",
      "B\n",
      "Accuracy of class 11: 0.95\n",
      "C\n",
      "Accuracy of class 12: 0.95\n",
      "D\n",
      "Accuracy of class 13: 0.91\n",
      "E\n",
      "Accuracy of class 14: 0.98\n",
      "F\n",
      "Accuracy of class 15: 0.47\n",
      "G\n",
      "Accuracy of class 16: 0.92\n",
      "H\n",
      "Accuracy of class 17: 0.97\n",
      "I\n",
      "Accuracy of class 18: 0.67\n",
      "J\n",
      "Accuracy of class 19: 0.92\n",
      "K\n",
      "Accuracy of class 20: 0.96\n",
      "L\n",
      "Accuracy of class 21: 0.46\n",
      "M\n",
      "Accuracy of class 22: 0.96\n",
      "N\n",
      "Accuracy of class 23: 0.97\n",
      "O\n",
      "Accuracy of class 24: 0.60\n",
      "P\n",
      "Accuracy of class 25: 0.96\n",
      "Q\n",
      "Accuracy of class 26: 0.93\n",
      "R\n",
      "Accuracy of class 27: 0.97\n",
      "S\n",
      "Accuracy of class 28: 0.90\n",
      "T\n",
      "Accuracy of class 29: 0.91\n",
      "U\n",
      "Accuracy of class 30: 0.93\n",
      "V\n",
      "Accuracy of class 31: 0.94\n",
      "W\n",
      "Accuracy of class 32: 0.98\n",
      "X\n",
      "Accuracy of class 33: 0.94\n",
      "Y\n",
      "Accuracy of class 34: 0.87\n",
      "Z\n",
      "Accuracy of class 35: 0.90\n",
      "a\n",
      "Accuracy of class 36: 0.89\n",
      "b\n",
      "Accuracy of class 37: 0.92\n",
      "d\n",
      "Accuracy of class 38: 0.95\n",
      "e\n",
      "Accuracy of class 39: 0.96\n",
      "f\n",
      "Accuracy of class 40: 0.74\n",
      "g\n",
      "Accuracy of class 41: 0.57\n",
      "h\n",
      "Accuracy of class 42: 0.93\n",
      "n\n",
      "Accuracy of class 43: 0.91\n",
      "q\n",
      "Accuracy of class 44: 0.45\n",
      "r\n",
      "Accuracy of class 45: 0.93\n",
      "t\n",
      "Accuracy of class 46: 0.92\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Инициализация переменных для хранения результатов\n",
    "class_correct = [0] * 47  # Для каждого из 47 классов\n",
    "class_total = [0] * 47\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "with torch.no_grad():\n",
    "    for data, target in val_loader:\n",
    "        output = model(data)  # Получение предсказаний от модели\n",
    "        _, predicted = torch.max(output, 1)  # Получение индексов классов с максимальным значением вероятности\n",
    "\n",
    "        # Подсчет правильных предсказаний для каждого класса\n",
    "        for i in range(len(target)):\n",
    "            label = target[i].item()  # Получение метки класса\n",
    "            class_correct[label] += (predicted[i] == label).item()  # Увеличение счетчика для правильного предсказания\n",
    "            class_total[label] += 1  # Увеличение общего количества примеров для данного класса\n",
    "\n",
    "# Вывод результатов по каждому классу\n",
    "for i in range(47):\n",
    "    if class_total[i] > 0:  # Избегаем деления на ноль\n",
    "        accuracy = class_correct[i] / class_total[i]\n",
    "        print(label_dict[i])\n",
    "        print(f'Accuracy of class {i}: {accuracy:.2f}')\n",
    "    else:\n",
    "        print(f'Class {i} has no samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41695861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes with accuracy < 0.87:\n",
      "0\n",
      "Accuracy of class 0: 0.74\n",
      "1\n",
      "Accuracy of class 1: 0.60\n",
      "F\n",
      "Accuracy of class 15: 0.47\n",
      "I\n",
      "Accuracy of class 18: 0.67\n",
      "L\n",
      "Accuracy of class 21: 0.46\n",
      "O\n",
      "Accuracy of class 24: 0.60\n",
      "Y\n",
      "Accuracy of class 34: 0.87\n",
      "f\n",
      "Accuracy of class 40: 0.74\n",
      "g\n",
      "Accuracy of class 41: 0.57\n",
      "q\n",
      "Accuracy of class 44: 0.45\n"
     ]
    }
   ],
   "source": [
    "# Вывод результатов по каждому классу с accuracy < 0.87\n",
    "print(\"Classes with accuracy < 0.87:\")\n",
    "for i in range(47):\n",
    "    if class_total[i] > 0:  # Избегаем деления на ноль\n",
    "        accuracy = class_correct[i] / class_total[i]\n",
    "        if accuracy < 0.87:  # Проверяем условие на точность\n",
    "            print(label_dict[i])  # Выводим метку класса\n",
    "            print(f'Accuracy of class {i}: {accuracy:.2f}')\n",
    "    else:\n",
    "        print(f'Class {i} has no samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a492f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели в формате .ckpt\n",
    "torch.save(model.state_dict(), 'model_rot_enh.ckpt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1455d713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6123/1479477111.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model_rot_enh.ckpt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка предварительно обученной модели\n",
    "model = ImprovedCNNModel()  # модель уже определена\n",
    "model.load_state_dict(torch.load('model_rot_enh.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6e37ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ImprovedCNNModel                         [1, 47]                   --\n",
       "├─Conv2d: 1-1                            [1, 32, 28, 28]           320\n",
       "├─BatchNorm2d: 1-2                       [1, 32, 28, 28]           64\n",
       "├─MaxPool2d: 1-3                         [1, 32, 14, 14]           --\n",
       "├─Conv2d: 1-4                            [1, 64, 14, 14]           18,496\n",
       "├─BatchNorm2d: 1-5                       [1, 64, 14, 14]           128\n",
       "├─MaxPool2d: 1-6                         [1, 64, 7, 7]             --\n",
       "├─Linear: 1-7                            [1, 128]                  401,536\n",
       "├─Linear: 1-8                            [1, 47]                   6,063\n",
       "==========================================================================================\n",
       "Total params: 426,607\n",
       "Trainable params: 426,607\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 4.28\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.60\n",
       "Params size (MB): 1.71\n",
       "Estimated Total Size (MB): 2.31\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вывод информации о модели\n",
    "summary(model, input_size=(1, 1, 28, 28))  # Указываем размер входного тензора [batch_size, channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4bf91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
